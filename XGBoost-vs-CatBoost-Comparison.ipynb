{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework2_inzva.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr-Z6RSwnDN6"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "import time\r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "IeeRbIVFrXfW",
        "outputId": "007f09e3-fc60-4c42-c48b-e271a661bf00"
      },
      "source": [
        "path = \"/content/train_transaction.csv\"\r\n",
        "df = pd.read_csv(path)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RnwC5Mpr7dP",
        "outputId": "0805452f-3886-4db0-8754-adfe447fe0af"
      },
      "source": [
        "print(df.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(590540, 394)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLvEIvcAnchV",
        "outputId": "c5718c42-9b2b-49bf-de99-ca79f3b14f53"
      },
      "source": [
        "print(df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 590540 entries, 0 to 590539\n",
            "Columns: 394 entries, TransactionID to V339\n",
            "dtypes: float64(376), int64(4), object(14)\n",
            "memory usage: 1.7+ GB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "opnwcW1asG22",
        "outputId": "b754ec39-e6b9-4de0-ff43-109abec33d63"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.905400e+05</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>5.905400e+05</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>581607.000000</td>\n",
              "      <td>588975.000000</td>\n",
              "      <td>586281.000000</td>\n",
              "      <td>524834.000000</td>\n",
              "      <td>524834.000000</td>\n",
              "      <td>238269.000000</td>\n",
              "      <td>37627.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>590540.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>309743.000000</td>\n",
              "      <td>327662.000000</td>\n",
              "      <td>421618.000000</td>\n",
              "      <td>280699.000000</td>\n",
              "      <td>73187.000000</td>\n",
              "      <td>38917.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>74926.000000</td>\n",
              "      <td>514518.000000</td>\n",
              "      <td>311253.000000</td>\n",
              "      <td>64717.000000</td>\n",
              "      <td>61952.000000</td>\n",
              "      <td>62187.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>589271.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>590528.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.00000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "      <td>82351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.282270e+06</td>\n",
              "      <td>0.034990</td>\n",
              "      <td>7.372311e+06</td>\n",
              "      <td>135.027176</td>\n",
              "      <td>9898.734658</td>\n",
              "      <td>362.555488</td>\n",
              "      <td>153.194925</td>\n",
              "      <td>199.278897</td>\n",
              "      <td>290.733794</td>\n",
              "      <td>86.800630</td>\n",
              "      <td>118.502180</td>\n",
              "      <td>231.855423</td>\n",
              "      <td>14.092458</td>\n",
              "      <td>15.269734</td>\n",
              "      <td>0.005644</td>\n",
              "      <td>4.092185</td>\n",
              "      <td>5.571526</td>\n",
              "      <td>9.071082</td>\n",
              "      <td>2.848478</td>\n",
              "      <td>5.144574</td>\n",
              "      <td>4.480240</td>\n",
              "      <td>5.240343</td>\n",
              "      <td>10.241521</td>\n",
              "      <td>4.076227</td>\n",
              "      <td>32.539918</td>\n",
              "      <td>8.295215</td>\n",
              "      <td>94.347568</td>\n",
              "      <td>169.563231</td>\n",
              "      <td>28.343348</td>\n",
              "      <td>140.002441</td>\n",
              "      <td>42.335965</td>\n",
              "      <td>69.805717</td>\n",
              "      <td>41.638950</td>\n",
              "      <td>146.058108</td>\n",
              "      <td>0.561057</td>\n",
              "      <td>123.982137</td>\n",
              "      <td>146.621465</td>\n",
              "      <td>54.037533</td>\n",
              "      <td>17.901295</td>\n",
              "      <td>57.724444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045507</td>\n",
              "      <td>0.052002</td>\n",
              "      <td>0.251761</td>\n",
              "      <td>0.283140</td>\n",
              "      <td>0.264208</td>\n",
              "      <td>1.000007</td>\n",
              "      <td>139.748713</td>\n",
              "      <td>408.682375</td>\n",
              "      <td>230.413180</td>\n",
              "      <td>10.995986</td>\n",
              "      <td>118.195658</td>\n",
              "      <td>4.202175</td>\n",
              "      <td>39.173910</td>\n",
              "      <td>21.351473</td>\n",
              "      <td>43.319174</td>\n",
              "      <td>26.806977</td>\n",
              "      <td>109.818544</td>\n",
              "      <td>247.606741</td>\n",
              "      <td>162.153398</td>\n",
              "      <td>18.372476</td>\n",
              "      <td>42.073133</td>\n",
              "      <td>28.326584</td>\n",
              "      <td>6.220289</td>\n",
              "      <td>13.103775</td>\n",
              "      <td>9.184612</td>\n",
              "      <td>0.058494</td>\n",
              "      <td>0.851040</td>\n",
              "      <td>0.296633</td>\n",
              "      <td>0.336790</td>\n",
              "      <td>1.312844</td>\n",
              "      <td>0.775874</td>\n",
              "      <td>721.741883</td>\n",
              "      <td>1375.783644</td>\n",
              "      <td>1014.622782</td>\n",
              "      <td>9.807015</td>\n",
              "      <td>59.16455</td>\n",
              "      <td>28.530903</td>\n",
              "      <td>55.352422</td>\n",
              "      <td>151.160542</td>\n",
              "      <td>100.700882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.704744e+05</td>\n",
              "      <td>0.183755</td>\n",
              "      <td>4.617224e+06</td>\n",
              "      <td>239.162522</td>\n",
              "      <td>4901.170153</td>\n",
              "      <td>157.793246</td>\n",
              "      <td>11.336444</td>\n",
              "      <td>41.244453</td>\n",
              "      <td>101.741072</td>\n",
              "      <td>2.690623</td>\n",
              "      <td>371.872026</td>\n",
              "      <td>529.053494</td>\n",
              "      <td>133.569018</td>\n",
              "      <td>154.668899</td>\n",
              "      <td>0.150536</td>\n",
              "      <td>68.848459</td>\n",
              "      <td>25.786976</td>\n",
              "      <td>71.508467</td>\n",
              "      <td>61.727304</td>\n",
              "      <td>95.378574</td>\n",
              "      <td>16.674897</td>\n",
              "      <td>95.581443</td>\n",
              "      <td>94.336292</td>\n",
              "      <td>86.666218</td>\n",
              "      <td>129.364844</td>\n",
              "      <td>49.544262</td>\n",
              "      <td>157.660387</td>\n",
              "      <td>177.315865</td>\n",
              "      <td>62.384721</td>\n",
              "      <td>191.096774</td>\n",
              "      <td>89.000144</td>\n",
              "      <td>143.669253</td>\n",
              "      <td>99.743264</td>\n",
              "      <td>231.663840</td>\n",
              "      <td>0.316880</td>\n",
              "      <td>182.615225</td>\n",
              "      <td>186.042622</td>\n",
              "      <td>124.274558</td>\n",
              "      <td>67.614425</td>\n",
              "      <td>136.312450</td>\n",
              "      <td>...</td>\n",
              "      <td>0.289573</td>\n",
              "      <td>0.318310</td>\n",
              "      <td>0.481889</td>\n",
              "      <td>0.623608</td>\n",
              "      <td>0.528238</td>\n",
              "      <td>0.002603</td>\n",
              "      <td>2348.849634</td>\n",
              "      <td>4391.992977</td>\n",
              "      <td>3021.924247</td>\n",
              "      <td>116.254277</td>\n",
              "      <td>352.983093</td>\n",
              "      <td>102.374938</td>\n",
              "      <td>172.128339</td>\n",
              "      <td>95.902970</td>\n",
              "      <td>173.619028</td>\n",
              "      <td>116.853222</td>\n",
              "      <td>2270.033202</td>\n",
              "      <td>3980.042828</td>\n",
              "      <td>2793.343636</td>\n",
              "      <td>332.304848</td>\n",
              "      <td>473.499307</td>\n",
              "      <td>382.053171</td>\n",
              "      <td>56.022561</td>\n",
              "      <td>106.739813</td>\n",
              "      <td>73.627893</td>\n",
              "      <td>0.304415</td>\n",
              "      <td>3.950295</td>\n",
              "      <td>1.364356</td>\n",
              "      <td>1.580144</td>\n",
              "      <td>8.769083</td>\n",
              "      <td>4.727971</td>\n",
              "      <td>6217.223583</td>\n",
              "      <td>11169.275702</td>\n",
              "      <td>7955.735482</td>\n",
              "      <td>243.861391</td>\n",
              "      <td>387.62948</td>\n",
              "      <td>274.576920</td>\n",
              "      <td>668.486833</td>\n",
              "      <td>1095.034387</td>\n",
              "      <td>814.946722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.987000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.640000e+04</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-53.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-193.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.134635e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.027058e+06</td>\n",
              "      <td>43.321000</td>\n",
              "      <td>6019.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.282270e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.306528e+06</td>\n",
              "      <td>68.769000</td>\n",
              "      <td>9678.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.875000</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.429904e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.124662e+07</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>14184.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>187.958328</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.380680</td>\n",
              "      <td>35.970001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.949997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.577539e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.581113e+07</td>\n",
              "      <td>31937.391000</td>\n",
              "      <td>18396.000000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>10286.000000</td>\n",
              "      <td>11623.000000</td>\n",
              "      <td>4685.000000</td>\n",
              "      <td>5691.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>2255.000000</td>\n",
              "      <td>3331.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>3257.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>1429.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>869.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>873.000000</td>\n",
              "      <td>843.000000</td>\n",
              "      <td>1707.791626</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>876.000000</td>\n",
              "      <td>670.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>847.000000</td>\n",
              "      <td>878.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>145765.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>7519.870117</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>93736.000000</td>\n",
              "      <td>134021.000000</td>\n",
              "      <td>98476.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>880.000000</td>\n",
              "      <td>1411.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.00000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 380 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       TransactionID        isFraud  ...           V338           V339\n",
              "count   5.905400e+05  590540.000000  ...   82351.000000   82351.000000\n",
              "mean    3.282270e+06       0.034990  ...     151.160542     100.700882\n",
              "std     1.704744e+05       0.183755  ...    1095.034387     814.946722\n",
              "min     2.987000e+06       0.000000  ...       0.000000       0.000000\n",
              "25%     3.134635e+06       0.000000  ...       0.000000       0.000000\n",
              "50%     3.282270e+06       0.000000  ...       0.000000       0.000000\n",
              "75%     3.429904e+06       0.000000  ...       0.000000       0.000000\n",
              "max     3.577539e+06       1.000000  ...  104060.000000  104060.000000\n",
              "\n",
              "[8 rows x 380 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9qkAObXsMXH",
        "outputId": "3784c906-b02b-4101-835c-725b8a438d90"
      },
      "source": [
        "# Keep only the rows with at least 75 percent non-NA values:\r\n",
        "\r\n",
        "df = df.dropna(axis=1, thresh=int(0.75*len(df)))\r\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 182)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkiJ7iIxsMcL",
        "outputId": "1ed35955-d7df-4de0-8171-f8d6a247372b"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransactionID      0\n",
              "isFraud            0\n",
              "TransactionDT      0\n",
              "TransactionAmt     0\n",
              "ProductCD          0\n",
              "                  ..\n",
              "V317              12\n",
              "V318              12\n",
              "V319              12\n",
              "V320              12\n",
              "V321              12\n",
              "Length: 182, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrgIKg8g8qj_",
        "outputId": "d27276bb-695b-4bd3-a908-8540e256fdc5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 182)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS7cxDxY58Vt"
      },
      "source": [
        "null_feature_list = []\r\n",
        "\r\n",
        "def null_colon_name(df):\r\n",
        "  for i in df.columns:\r\n",
        "    print(i,df[i].isnull().sum())\r\n",
        "    if df[i].isnull().sum() !=0:\r\n",
        "      null_feature_list.append(i)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUZtVvnF6VkK",
        "outputId": "243e1d83-d499-40da-c143-b176ab212c76"
      },
      "source": [
        "null_colon_name(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TransactionID 0\n",
            "isFraud 0\n",
            "TransactionDT 0\n",
            "TransactionAmt 0\n",
            "ProductCD 0\n",
            "card1 0\n",
            "card2 8933\n",
            "card3 1565\n",
            "card4 1577\n",
            "card5 4259\n",
            "card6 1571\n",
            "addr1 65706\n",
            "addr2 65706\n",
            "P_emaildomain 94456\n",
            "C1 0\n",
            "C2 0\n",
            "C3 0\n",
            "C4 0\n",
            "C5 0\n",
            "C6 0\n",
            "C7 0\n",
            "C8 0\n",
            "C9 0\n",
            "C10 0\n",
            "C11 0\n",
            "C12 0\n",
            "C13 0\n",
            "C14 0\n",
            "D1 1269\n",
            "D10 76022\n",
            "D15 89113\n",
            "V12 76073\n",
            "V13 76073\n",
            "V14 76073\n",
            "V15 76073\n",
            "V16 76073\n",
            "V17 76073\n",
            "V18 76073\n",
            "V19 76073\n",
            "V20 76073\n",
            "V21 76073\n",
            "V22 76073\n",
            "V23 76073\n",
            "V24 76073\n",
            "V25 76073\n",
            "V26 76073\n",
            "V27 76073\n",
            "V28 76073\n",
            "V29 76073\n",
            "V30 76073\n",
            "V31 76073\n",
            "V32 76073\n",
            "V33 76073\n",
            "V34 76073\n",
            "V53 77096\n",
            "V54 77096\n",
            "V55 77096\n",
            "V56 77096\n",
            "V57 77096\n",
            "V58 77096\n",
            "V59 77096\n",
            "V60 77096\n",
            "V61 77096\n",
            "V62 77096\n",
            "V63 77096\n",
            "V64 77096\n",
            "V65 77096\n",
            "V66 77096\n",
            "V67 77096\n",
            "V68 77096\n",
            "V69 77096\n",
            "V70 77096\n",
            "V71 77096\n",
            "V72 77096\n",
            "V73 77096\n",
            "V74 77096\n",
            "V75 89164\n",
            "V76 89164\n",
            "V77 89164\n",
            "V78 89164\n",
            "V79 89164\n",
            "V80 89164\n",
            "V81 89164\n",
            "V82 89164\n",
            "V83 89164\n",
            "V84 89164\n",
            "V85 89164\n",
            "V86 89164\n",
            "V87 89164\n",
            "V88 89164\n",
            "V89 89164\n",
            "V90 89164\n",
            "V91 89164\n",
            "V92 89164\n",
            "V93 89164\n",
            "V94 89164\n",
            "V95 314\n",
            "V96 314\n",
            "V97 314\n",
            "V98 314\n",
            "V99 314\n",
            "V100 314\n",
            "V101 314\n",
            "V102 314\n",
            "V103 314\n",
            "V104 314\n",
            "V105 314\n",
            "V106 314\n",
            "V107 314\n",
            "V108 314\n",
            "V109 314\n",
            "V110 314\n",
            "V111 314\n",
            "V112 314\n",
            "V113 314\n",
            "V114 314\n",
            "V115 314\n",
            "V116 314\n",
            "V117 314\n",
            "V118 314\n",
            "V119 314\n",
            "V120 314\n",
            "V121 314\n",
            "V122 314\n",
            "V123 314\n",
            "V124 314\n",
            "V125 314\n",
            "V126 314\n",
            "V127 314\n",
            "V128 314\n",
            "V129 314\n",
            "V130 314\n",
            "V131 314\n",
            "V132 314\n",
            "V133 314\n",
            "V134 314\n",
            "V135 314\n",
            "V136 314\n",
            "V137 314\n",
            "V279 12\n",
            "V280 12\n",
            "V281 1269\n",
            "V282 1269\n",
            "V283 1269\n",
            "V284 12\n",
            "V285 12\n",
            "V286 12\n",
            "V287 12\n",
            "V288 1269\n",
            "V289 1269\n",
            "V290 12\n",
            "V291 12\n",
            "V292 12\n",
            "V293 12\n",
            "V294 12\n",
            "V295 12\n",
            "V296 1269\n",
            "V297 12\n",
            "V298 12\n",
            "V299 12\n",
            "V300 1269\n",
            "V301 1269\n",
            "V302 12\n",
            "V303 12\n",
            "V304 12\n",
            "V305 12\n",
            "V306 12\n",
            "V307 12\n",
            "V308 12\n",
            "V309 12\n",
            "V310 12\n",
            "V311 12\n",
            "V312 12\n",
            "V313 1269\n",
            "V314 1269\n",
            "V315 1269\n",
            "V316 12\n",
            "V317 12\n",
            "V318 12\n",
            "V319 12\n",
            "V320 12\n",
            "V321 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkFUKnV81X6",
        "outputId": "9b3fe79e-e4b4-4ba7-c80b-d0f08738bef8"
      },
      "source": [
        "null_feature_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['card2',\n",
              " 'card3',\n",
              " 'card4',\n",
              " 'card5',\n",
              " 'card6',\n",
              " 'addr1',\n",
              " 'addr2',\n",
              " 'P_emaildomain',\n",
              " 'D1',\n",
              " 'D10',\n",
              " 'D15',\n",
              " 'V12',\n",
              " 'V13',\n",
              " 'V14',\n",
              " 'V15',\n",
              " 'V16',\n",
              " 'V17',\n",
              " 'V18',\n",
              " 'V19',\n",
              " 'V20',\n",
              " 'V21',\n",
              " 'V22',\n",
              " 'V23',\n",
              " 'V24',\n",
              " 'V25',\n",
              " 'V26',\n",
              " 'V27',\n",
              " 'V28',\n",
              " 'V29',\n",
              " 'V30',\n",
              " 'V31',\n",
              " 'V32',\n",
              " 'V33',\n",
              " 'V34',\n",
              " 'V53',\n",
              " 'V54',\n",
              " 'V55',\n",
              " 'V56',\n",
              " 'V57',\n",
              " 'V58',\n",
              " 'V59',\n",
              " 'V60',\n",
              " 'V61',\n",
              " 'V62',\n",
              " 'V63',\n",
              " 'V64',\n",
              " 'V65',\n",
              " 'V66',\n",
              " 'V67',\n",
              " 'V68',\n",
              " 'V69',\n",
              " 'V70',\n",
              " 'V71',\n",
              " 'V72',\n",
              " 'V73',\n",
              " 'V74',\n",
              " 'V75',\n",
              " 'V76',\n",
              " 'V77',\n",
              " 'V78',\n",
              " 'V79',\n",
              " 'V80',\n",
              " 'V81',\n",
              " 'V82',\n",
              " 'V83',\n",
              " 'V84',\n",
              " 'V85',\n",
              " 'V86',\n",
              " 'V87',\n",
              " 'V88',\n",
              " 'V89',\n",
              " 'V90',\n",
              " 'V91',\n",
              " 'V92',\n",
              " 'V93',\n",
              " 'V94',\n",
              " 'V95',\n",
              " 'V96',\n",
              " 'V97',\n",
              " 'V98',\n",
              " 'V99',\n",
              " 'V100',\n",
              " 'V101',\n",
              " 'V102',\n",
              " 'V103',\n",
              " 'V104',\n",
              " 'V105',\n",
              " 'V106',\n",
              " 'V107',\n",
              " 'V108',\n",
              " 'V109',\n",
              " 'V110',\n",
              " 'V111',\n",
              " 'V112',\n",
              " 'V113',\n",
              " 'V114',\n",
              " 'V115',\n",
              " 'V116',\n",
              " 'V117',\n",
              " 'V118',\n",
              " 'V119',\n",
              " 'V120',\n",
              " 'V121',\n",
              " 'V122',\n",
              " 'V123',\n",
              " 'V124',\n",
              " 'V125',\n",
              " 'V126',\n",
              " 'V127',\n",
              " 'V128',\n",
              " 'V129',\n",
              " 'V130',\n",
              " 'V131',\n",
              " 'V132',\n",
              " 'V133',\n",
              " 'V134',\n",
              " 'V135',\n",
              " 'V136',\n",
              " 'V137',\n",
              " 'V279',\n",
              " 'V280',\n",
              " 'V281',\n",
              " 'V282',\n",
              " 'V283',\n",
              " 'V284',\n",
              " 'V285',\n",
              " 'V286',\n",
              " 'V287',\n",
              " 'V288',\n",
              " 'V289',\n",
              " 'V290',\n",
              " 'V291',\n",
              " 'V292',\n",
              " 'V293',\n",
              " 'V294',\n",
              " 'V295',\n",
              " 'V296',\n",
              " 'V297',\n",
              " 'V298',\n",
              " 'V299',\n",
              " 'V300',\n",
              " 'V301',\n",
              " 'V302',\n",
              " 'V303',\n",
              " 'V304',\n",
              " 'V305',\n",
              " 'V306',\n",
              " 'V307',\n",
              " 'V308',\n",
              " 'V309',\n",
              " 'V310',\n",
              " 'V311',\n",
              " 'V312',\n",
              " 'V313',\n",
              " 'V314',\n",
              " 'V315',\n",
              " 'V316',\n",
              " 'V317',\n",
              " 'V318',\n",
              " 'V319',\n",
              " 'V320',\n",
              " 'V321']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1atTYior2NDE"
      },
      "source": [
        "for i in null_feature_list:\r\n",
        "  df[i] = df[i].fillna(\"non_value\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2eCqh1-yVr4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "# creating instance of labelencoder\r\n",
        "labelencoder = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "M1Jbnu4e3mp0",
        "outputId": "7c99dcbe-0d6d-446e-8924-5075576afe51"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D10</th>\n",
              "      <th>D15</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>...</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>non_value</td>\n",
              "      <td>150</td>\n",
              "      <td>discover</td>\n",
              "      <td>142</td>\n",
              "      <td>credit</td>\n",
              "      <td>315</td>\n",
              "      <td>87</td>\n",
              "      <td>non_value</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404</td>\n",
              "      <td>150</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102</td>\n",
              "      <td>credit</td>\n",
              "      <td>325</td>\n",
              "      <td>87</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490</td>\n",
              "      <td>150</td>\n",
              "      <td>visa</td>\n",
              "      <td>166</td>\n",
              "      <td>debit</td>\n",
              "      <td>330</td>\n",
              "      <td>87</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567</td>\n",
              "      <td>150</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117</td>\n",
              "      <td>debit</td>\n",
              "      <td>476</td>\n",
              "      <td>87</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112</td>\n",
              "      <td>84</td>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>1758</td>\n",
              "      <td>925</td>\n",
              "      <td>0</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1404</td>\n",
              "      <td>790</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514</td>\n",
              "      <td>150</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102</td>\n",
              "      <td>credit</td>\n",
              "      <td>420</td>\n",
              "      <td>87</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>non_value</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 182 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt  ... V318  V319 V320 V321\n",
              "0        2987000        0          86400            68.5  ...    0     0    0    0\n",
              "1        2987001        0          86401            29.0  ...    0     0    0    0\n",
              "2        2987002        0          86469            59.0  ...    0     0    0    0\n",
              "3        2987003        0          86499            50.0  ...  790     0    0    0\n",
              "4        2987004        0          86506            50.0  ...    0     0    0    0\n",
              "\n",
              "[5 rows x 182 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErxRbcla0PIh"
      },
      "source": [
        "# Assigning numerical values and storing in another column\r\n",
        "df['ProductCD'] = labelencoder.fit_transform(df['ProductCD'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLyAlIL2mXb"
      },
      "source": [
        "df['card4']= labelencoder.fit_transform(df['card4'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg7el5F8QgJJ"
      },
      "source": [
        "df['card6']= labelencoder.fit_transform(df['card6'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lanLlbZTQi12"
      },
      "source": [
        "df['P_emaildomain']= labelencoder.fit_transform(df['P_emaildomain'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33EK6Zlz78G0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRWBhYsucPwX"
      },
      "source": [
        "y = df[\"isFraud\"]\r\n",
        "df.drop([\"TransactionID\",\t\"isFraud\",\t\"TransactionDT\"], axis = 1, inplace=True)\r\n",
        "X = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOU_x5mDsG-T"
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GxS838IsHCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bf4343-00b7-40e9-c0f1-8a6f109150a4"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "\r\n",
        "for f in tqdm(X_train.columns):\r\n",
        "        \r\n",
        "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \r\n",
        "        lbl = LabelEncoder()\r\n",
        "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\r\n",
        "        X_train[f] = lbl.transform(list(X_train[f].values))\r\n",
        "        \r\n",
        "        X_test[f] = lbl.transform(list(X_test[f].values))  \r\n",
        "\r\n",
        "X_train.reset_index(inplace=True)\r\n",
        "X_test.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/179 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "100%|██████████| 179/179 [10:01<00:00,  3.36s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAlOse5OsHF3"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Ie53T5mgUX",
        "outputId": "bf099895-d219-460f-9714-453d1c4e4f46"
      },
      "source": [
        "X_train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index             0\n",
              "TransactionAmt    0\n",
              "ProductCD         0\n",
              "card1             0\n",
              "card2             0\n",
              "                 ..\n",
              "V317              0\n",
              "V318              0\n",
              "V319              0\n",
              "V320              0\n",
              "V321              0\n",
              "Length: 180, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1Qf_gWiev8"
      },
      "source": [
        "# Train the XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbGeKzjsiVeU",
        "outputId": "060b8739-d33f-4eda-b47f-423f969dc57a"
      },
      "source": [
        "# fit model  training data\r\n",
        "model_xgboost = XGBClassifier(tree_method = 'hist',verbose=10)\r\n",
        "model_xgboost.fit(X_train, y_train)\r\n",
        "print(model_xgboost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, tree_method='hist', verbose=10,\n",
            "              verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqvSuvJVzvUa"
      },
      "source": [
        "# Make Predictions with XGBoost (default parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrMxDWrVzrMD",
        "outputId": "72429897-cb94-4611-dbb0-c6a96aeba17c"
      },
      "source": [
        "# make predictions for test data\r\n",
        "y_pred = model_xgboost.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n",
        "\r\n",
        "# make predictions for test data\r\n",
        "y_pred = model_xgboost.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n",
        "\r\n",
        "# evaluate predictions\r\n",
        "accuracy = accuracy_score(y_test, predictions)\r\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\r\n",
        "\r\n",
        "# conusion matrix\r\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 97.25%\n",
            "[[187645    288]\n",
            " [  5072   1874]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCHBU61skQej"
      },
      "source": [
        "# Grid Search Kullanarak Parametre **Optimizasyonu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YebvnEc5z1lk",
        "outputId": "0e91bdad-124f-4317-f52f-13f2493d49c7"
      },
      "source": [
        "xgboost_gridsearch = GridSearchCV(model_xgboost,{'max_depth': [4,6],\r\n",
        "                    'n_estimators': [50,100],\r\n",
        "                    'min_child_weight': [5, 10],\r\n",
        "                    'gamma': [0.5, 1, 1.5]}, \r\n",
        "                    verbose=10, \r\n",
        "                    scoring='neg_log_loss',\r\n",
        "                    cv=2)\r\n",
        "\r\n",
        "search_time_start = time.time()\r\n",
        "xgboost_gridsearch.fit(X_train, y_train)\r\n",
        "print(\"Grid search time:\", time.time() - search_time_start)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=50 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.100, total=  13.2s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=50 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.101, total=  13.4s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=100 ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   26.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.092, total=  22.0s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=100 ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   48.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.093, total=  21.7s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=50 ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.100, total=  13.2s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=50 ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.101, total=  12.5s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=100 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.092, total=  21.2s\n",
            "[CV] gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=100 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.093, total=  21.1s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=50 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.092, total=  18.0s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=50 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.092, total=  17.6s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.084, total=  28.7s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.085, total=  29.1s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.092, total=  16.9s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.093, total=  16.8s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.085, total=  27.4s\n",
            "[CV] gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=0.5, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.086, total=  29.3s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=5, n_estimators=50 .......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.100, total=  13.2s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=5, n_estimators=50 .......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.101, total=  13.0s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=5, n_estimators=100 ......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.092, total=  21.3s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=5, n_estimators=100 ......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.093, total=  21.3s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=10, n_estimators=50 ......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.100, total=  12.6s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=10, n_estimators=50 ......\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.101, total=  12.4s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=10, n_estimators=100 .....\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.093, total=  21.2s\n",
            "[CV] gamma=1, max_depth=4, min_child_weight=10, n_estimators=100 .....\n",
            "[CV]  gamma=1, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.093, total=  21.8s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=5, n_estimators=50 .......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.092, total=  17.3s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=5, n_estimators=50 .......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.093, total=  17.1s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=5, n_estimators=100 ......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.084, total=  28.1s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=5, n_estimators=100 ......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.085, total=  28.9s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=10, n_estimators=50 ......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.092, total=  17.5s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=10, n_estimators=50 ......\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.093, total=  17.7s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=10, n_estimators=100 .....\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.085, total=  27.8s\n",
            "[CV] gamma=1, max_depth=6, min_child_weight=10, n_estimators=100 .....\n",
            "[CV]  gamma=1, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.086, total=  29.5s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=50 .....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.100, total=  13.4s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=50 .....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=50, score=-0.101, total=  13.4s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.092, total=  21.6s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=5, n_estimators=100, score=-0.093, total=  21.8s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.100, total=  13.7s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=50, score=-0.101, total=  13.0s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.092, total=  22.0s\n",
            "[CV] gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=1.5, max_depth=4, min_child_weight=10, n_estimators=100, score=-0.093, total=  21.9s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=50 .....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.092, total=  17.6s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=50 .....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=50, score=-0.092, total=  16.6s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.084, total=  29.5s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=100 ....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=5, n_estimators=100, score=-0.085, total=  27.7s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.092, total=  17.8s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=50 ....\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=50, score=-0.093, total=  17.8s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.085, total=  27.8s\n",
            "[CV] gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=100 ...\n",
            "[CV]  gamma=1.5, max_depth=6, min_child_weight=10, n_estimators=100, score=-0.086, total=  28.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 16.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Grid search time: 1019.2579503059387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__zS7uDo4E3",
        "outputId": "2513385c-5b4b-470a-cfac-609a9ccca441"
      },
      "source": [
        "# summarize result\r\n",
        "print('Best Score: %s' % xgboost_gridsearch.best_score_)\r\n",
        "print('Best Hyperparameters: %s' % xgboost_gridsearch.best_params_)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score: -0.08441821378095077\n",
            "Best Hyperparameters: {'gamma': 1.5, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frq5go0Jwupc",
        "outputId": "0b4222b3-4d78-4038-9004-7f6778ebab2e"
      },
      "source": [
        "model_xgboost_hyp_opt = XGBClassifier(tree_method = 'hist',verbose=10,gamma= 1.5, max_depth= 6, min_child_weight= 5, n_estimators= 100)\r\n",
        "model_xgboost_hyp_opt.fit(X_train, y_train)\r\n",
        "print(model_xgboost_hyp_opt)\r\n",
        "\r\n",
        "# make predictions for test data\r\n",
        "y_pred = model_xgboost_hyp_opt.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n",
        "\r\n",
        "# make predictions for test data\r\n",
        "y_pred = model_xgboost_hyp_opt.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n",
        "\r\n",
        "# evaluate predictions\r\n",
        "accuracy = accuracy_score(y_test, predictions)\r\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\r\n",
        "\r\n",
        "# conusion matrix\r\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=1.5,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
            "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, tree_method='hist', verbose=10,\n",
            "              verbosity=1)\n",
            "Accuracy: 97.65%\n",
            "[[187600    333]\n",
            " [  4246   2700]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adQj0u0S0VHV"
      },
      "source": [
        "## MODEL CatBoostClassifier (default parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IoEFwWk0Xuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e020e5a8-cf32-4a53-a11b-c1649fde6999"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.4)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv09TkIz7P1"
      },
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjmAZW3w0WpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6ff61c-3909-4064-ad67-1314e4a77e9e"
      },
      "source": [
        "#  Fit model\r\n",
        "model_catboost = CatBoostClassifier()\r\n",
        "model_catboost.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(model_catboost)\r\n",
        "\r\n",
        "# make predictions for test data\r\n",
        "y_pred = model_catboost.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n",
        "\r\n",
        "# make predictions for test data\r\n",
        "y_pred = model_catboost.predict(X_test)\r\n",
        "predictions = [round(value) for value in y_pred]\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.132431\n",
            "0:\tlearn: 0.4959070\ttotal: 397ms\tremaining: 6m 37s\n",
            "1:\tlearn: 0.3738750\ttotal: 693ms\tremaining: 5m 45s\n",
            "2:\tlearn: 0.2812656\ttotal: 1.04s\tremaining: 5m 46s\n",
            "3:\tlearn: 0.2288223\ttotal: 1.4s\tremaining: 5m 47s\n",
            "4:\tlearn: 0.1940739\ttotal: 1.73s\tremaining: 5m 43s\n",
            "5:\tlearn: 0.1670806\ttotal: 2.07s\tremaining: 5m 42s\n",
            "6:\tlearn: 0.1494067\ttotal: 2.42s\tremaining: 5m 43s\n",
            "7:\tlearn: 0.1387088\ttotal: 2.78s\tremaining: 5m 44s\n",
            "8:\tlearn: 0.1306688\ttotal: 3.11s\tremaining: 5m 42s\n",
            "9:\tlearn: 0.1250569\ttotal: 3.43s\tremaining: 5m 39s\n",
            "10:\tlearn: 0.1203950\ttotal: 3.78s\tremaining: 5m 39s\n",
            "11:\tlearn: 0.1163447\ttotal: 4.21s\tremaining: 5m 46s\n",
            "12:\tlearn: 0.1135038\ttotal: 4.66s\tremaining: 5m 53s\n",
            "13:\tlearn: 0.1112289\ttotal: 5.09s\tremaining: 5m 58s\n",
            "14:\tlearn: 0.1093189\ttotal: 5.51s\tremaining: 6m 1s\n",
            "15:\tlearn: 0.1079711\ttotal: 5.87s\tremaining: 6m\n",
            "16:\tlearn: 0.1064014\ttotal: 6.3s\tremaining: 6m 4s\n",
            "17:\tlearn: 0.1053914\ttotal: 6.68s\tremaining: 6m 4s\n",
            "18:\tlearn: 0.1045758\ttotal: 7.08s\tremaining: 6m 5s\n",
            "19:\tlearn: 0.1039482\ttotal: 7.46s\tremaining: 6m 5s\n",
            "20:\tlearn: 0.1030572\ttotal: 7.88s\tremaining: 6m 7s\n",
            "21:\tlearn: 0.1022448\ttotal: 8.27s\tremaining: 6m 7s\n",
            "22:\tlearn: 0.1017006\ttotal: 8.63s\tremaining: 6m 6s\n",
            "23:\tlearn: 0.1012727\ttotal: 9s\tremaining: 6m 6s\n",
            "24:\tlearn: 0.1008528\ttotal: 9.36s\tremaining: 6m 5s\n",
            "25:\tlearn: 0.1005109\ttotal: 9.71s\tremaining: 6m 3s\n",
            "26:\tlearn: 0.1001588\ttotal: 10s\tremaining: 6m 1s\n",
            "27:\tlearn: 0.0997849\ttotal: 10.4s\tremaining: 5m 59s\n",
            "28:\tlearn: 0.0994789\ttotal: 10.7s\tremaining: 5m 58s\n",
            "29:\tlearn: 0.0991460\ttotal: 11.1s\tremaining: 5m 57s\n",
            "30:\tlearn: 0.0987562\ttotal: 11.4s\tremaining: 5m 56s\n",
            "31:\tlearn: 0.0984914\ttotal: 11.8s\tremaining: 5m 55s\n",
            "32:\tlearn: 0.0981643\ttotal: 12.1s\tremaining: 5m 54s\n",
            "33:\tlearn: 0.0977584\ttotal: 12.5s\tremaining: 5m 54s\n",
            "34:\tlearn: 0.0975713\ttotal: 12.8s\tremaining: 5m 53s\n",
            "35:\tlearn: 0.0973100\ttotal: 13.2s\tremaining: 5m 53s\n",
            "36:\tlearn: 0.0969265\ttotal: 13.6s\tremaining: 5m 53s\n",
            "37:\tlearn: 0.0967043\ttotal: 14s\tremaining: 5m 53s\n",
            "38:\tlearn: 0.0966228\ttotal: 14.2s\tremaining: 5m 50s\n",
            "39:\tlearn: 0.0963688\ttotal: 14.6s\tremaining: 5m 50s\n",
            "40:\tlearn: 0.0962450\ttotal: 14.9s\tremaining: 5m 49s\n",
            "41:\tlearn: 0.0959341\ttotal: 15.3s\tremaining: 5m 49s\n",
            "42:\tlearn: 0.0956722\ttotal: 15.7s\tremaining: 5m 48s\n",
            "43:\tlearn: 0.0954992\ttotal: 16s\tremaining: 5m 48s\n",
            "44:\tlearn: 0.0953252\ttotal: 16.4s\tremaining: 5m 47s\n",
            "45:\tlearn: 0.0952114\ttotal: 16.7s\tremaining: 5m 45s\n",
            "46:\tlearn: 0.0950173\ttotal: 17s\tremaining: 5m 45s\n",
            "47:\tlearn: 0.0947995\ttotal: 17.4s\tremaining: 5m 44s\n",
            "48:\tlearn: 0.0946631\ttotal: 17.7s\tremaining: 5m 43s\n",
            "49:\tlearn: 0.0944331\ttotal: 18.1s\tremaining: 5m 43s\n",
            "50:\tlearn: 0.0942372\ttotal: 18.5s\tremaining: 5m 43s\n",
            "51:\tlearn: 0.0941177\ttotal: 18.8s\tremaining: 5m 41s\n",
            "52:\tlearn: 0.0939713\ttotal: 19.1s\tremaining: 5m 40s\n",
            "53:\tlearn: 0.0938122\ttotal: 19.4s\tremaining: 5m 39s\n",
            "54:\tlearn: 0.0936220\ttotal: 19.8s\tremaining: 5m 39s\n",
            "55:\tlearn: 0.0934271\ttotal: 20.1s\tremaining: 5m 38s\n",
            "56:\tlearn: 0.0933007\ttotal: 20.4s\tremaining: 5m 37s\n",
            "57:\tlearn: 0.0931710\ttotal: 20.8s\tremaining: 5m 37s\n",
            "58:\tlearn: 0.0930320\ttotal: 21.2s\tremaining: 5m 37s\n",
            "59:\tlearn: 0.0929142\ttotal: 21.5s\tremaining: 5m 37s\n",
            "60:\tlearn: 0.0927073\ttotal: 21.9s\tremaining: 5m 37s\n",
            "61:\tlearn: 0.0925086\ttotal: 22.3s\tremaining: 5m 37s\n",
            "62:\tlearn: 0.0924126\ttotal: 22.6s\tremaining: 5m 36s\n",
            "63:\tlearn: 0.0921721\ttotal: 23s\tremaining: 5m 36s\n",
            "64:\tlearn: 0.0920965\ttotal: 23.3s\tremaining: 5m 35s\n",
            "65:\tlearn: 0.0918903\ttotal: 23.7s\tremaining: 5m 35s\n",
            "66:\tlearn: 0.0918417\ttotal: 24s\tremaining: 5m 34s\n",
            "67:\tlearn: 0.0917203\ttotal: 24.4s\tremaining: 5m 33s\n",
            "68:\tlearn: 0.0916372\ttotal: 24.7s\tremaining: 5m 33s\n",
            "69:\tlearn: 0.0914364\ttotal: 25.1s\tremaining: 5m 33s\n",
            "70:\tlearn: 0.0913399\ttotal: 25.4s\tremaining: 5m 32s\n",
            "71:\tlearn: 0.0912399\ttotal: 25.8s\tremaining: 5m 32s\n",
            "72:\tlearn: 0.0911158\ttotal: 26.1s\tremaining: 5m 31s\n",
            "73:\tlearn: 0.0909930\ttotal: 26.4s\tremaining: 5m 30s\n",
            "74:\tlearn: 0.0908906\ttotal: 26.8s\tremaining: 5m 30s\n",
            "75:\tlearn: 0.0908060\ttotal: 27.2s\tremaining: 5m 30s\n",
            "76:\tlearn: 0.0907556\ttotal: 27.5s\tremaining: 5m 29s\n",
            "77:\tlearn: 0.0906231\ttotal: 27.8s\tremaining: 5m 28s\n",
            "78:\tlearn: 0.0905071\ttotal: 28.1s\tremaining: 5m 28s\n",
            "79:\tlearn: 0.0904204\ttotal: 28.5s\tremaining: 5m 27s\n",
            "80:\tlearn: 0.0903400\ttotal: 28.8s\tremaining: 5m 27s\n",
            "81:\tlearn: 0.0901743\ttotal: 29.2s\tremaining: 5m 26s\n",
            "82:\tlearn: 0.0900253\ttotal: 29.5s\tremaining: 5m 25s\n",
            "83:\tlearn: 0.0899481\ttotal: 29.8s\tremaining: 5m 25s\n",
            "84:\tlearn: 0.0897659\ttotal: 30.2s\tremaining: 5m 25s\n",
            "85:\tlearn: 0.0896617\ttotal: 30.6s\tremaining: 5m 24s\n",
            "86:\tlearn: 0.0895766\ttotal: 30.9s\tremaining: 5m 24s\n",
            "87:\tlearn: 0.0894265\ttotal: 31.3s\tremaining: 5m 23s\n",
            "88:\tlearn: 0.0892797\ttotal: 31.6s\tremaining: 5m 23s\n",
            "89:\tlearn: 0.0891720\ttotal: 32s\tremaining: 5m 23s\n",
            "90:\tlearn: 0.0891198\ttotal: 32.3s\tremaining: 5m 22s\n",
            "91:\tlearn: 0.0890197\ttotal: 32.6s\tremaining: 5m 22s\n",
            "92:\tlearn: 0.0889420\ttotal: 33s\tremaining: 5m 22s\n",
            "93:\tlearn: 0.0888893\ttotal: 33.3s\tremaining: 5m 21s\n",
            "94:\tlearn: 0.0887660\ttotal: 33.8s\tremaining: 5m 21s\n",
            "95:\tlearn: 0.0886551\ttotal: 34.1s\tremaining: 5m 21s\n",
            "96:\tlearn: 0.0885942\ttotal: 34.5s\tremaining: 5m 20s\n",
            "97:\tlearn: 0.0884892\ttotal: 34.8s\tremaining: 5m 20s\n",
            "98:\tlearn: 0.0883788\ttotal: 35.2s\tremaining: 5m 20s\n",
            "99:\tlearn: 0.0883186\ttotal: 35.5s\tremaining: 5m 19s\n",
            "100:\tlearn: 0.0882142\ttotal: 35.9s\tremaining: 5m 19s\n",
            "101:\tlearn: 0.0881048\ttotal: 36.3s\tremaining: 5m 19s\n",
            "102:\tlearn: 0.0880258\ttotal: 36.6s\tremaining: 5m 18s\n",
            "103:\tlearn: 0.0879196\ttotal: 37s\tremaining: 5m 18s\n",
            "104:\tlearn: 0.0878258\ttotal: 37.4s\tremaining: 5m 18s\n",
            "105:\tlearn: 0.0877097\ttotal: 37.7s\tremaining: 5m 17s\n",
            "106:\tlearn: 0.0876145\ttotal: 38s\tremaining: 5m 17s\n",
            "107:\tlearn: 0.0875320\ttotal: 38.4s\tremaining: 5m 16s\n",
            "108:\tlearn: 0.0874413\ttotal: 38.7s\tremaining: 5m 16s\n",
            "109:\tlearn: 0.0874000\ttotal: 39.1s\tremaining: 5m 16s\n",
            "110:\tlearn: 0.0873121\ttotal: 39.4s\tremaining: 5m 15s\n",
            "111:\tlearn: 0.0872265\ttotal: 39.8s\tremaining: 5m 15s\n",
            "112:\tlearn: 0.0871292\ttotal: 40.2s\tremaining: 5m 15s\n",
            "113:\tlearn: 0.0870046\ttotal: 40.6s\tremaining: 5m 15s\n",
            "114:\tlearn: 0.0869561\ttotal: 40.9s\tremaining: 5m 14s\n",
            "115:\tlearn: 0.0868569\ttotal: 41.2s\tremaining: 5m 14s\n",
            "116:\tlearn: 0.0867491\ttotal: 41.6s\tremaining: 5m 13s\n",
            "117:\tlearn: 0.0866270\ttotal: 41.9s\tremaining: 5m 13s\n",
            "118:\tlearn: 0.0865760\ttotal: 42.2s\tremaining: 5m 12s\n",
            "119:\tlearn: 0.0864948\ttotal: 42.6s\tremaining: 5m 12s\n",
            "120:\tlearn: 0.0864205\ttotal: 42.9s\tremaining: 5m 11s\n",
            "121:\tlearn: 0.0863028\ttotal: 43.3s\tremaining: 5m 11s\n",
            "122:\tlearn: 0.0861979\ttotal: 43.6s\tremaining: 5m 11s\n",
            "123:\tlearn: 0.0861382\ttotal: 44s\tremaining: 5m 10s\n",
            "124:\tlearn: 0.0860661\ttotal: 44.4s\tremaining: 5m 10s\n",
            "125:\tlearn: 0.0860282\ttotal: 44.6s\tremaining: 5m 9s\n",
            "126:\tlearn: 0.0859247\ttotal: 45s\tremaining: 5m 9s\n",
            "127:\tlearn: 0.0858361\ttotal: 45.4s\tremaining: 5m 9s\n",
            "128:\tlearn: 0.0857787\ttotal: 45.7s\tremaining: 5m 8s\n",
            "129:\tlearn: 0.0856731\ttotal: 46.1s\tremaining: 5m 8s\n",
            "130:\tlearn: 0.0856384\ttotal: 46.4s\tremaining: 5m 7s\n",
            "131:\tlearn: 0.0855234\ttotal: 46.8s\tremaining: 5m 7s\n",
            "132:\tlearn: 0.0854288\ttotal: 47.2s\tremaining: 5m 7s\n",
            "133:\tlearn: 0.0853477\ttotal: 47.6s\tremaining: 5m 7s\n",
            "134:\tlearn: 0.0852808\ttotal: 47.9s\tremaining: 5m 7s\n",
            "135:\tlearn: 0.0852358\ttotal: 48.3s\tremaining: 5m 6s\n",
            "136:\tlearn: 0.0852054\ttotal: 48.6s\tremaining: 5m 6s\n",
            "137:\tlearn: 0.0851447\ttotal: 49s\tremaining: 5m 5s\n",
            "138:\tlearn: 0.0850470\ttotal: 49.4s\tremaining: 5m 5s\n",
            "139:\tlearn: 0.0849882\ttotal: 49.7s\tremaining: 5m 5s\n",
            "140:\tlearn: 0.0848914\ttotal: 50.1s\tremaining: 5m 5s\n",
            "141:\tlearn: 0.0847625\ttotal: 50.6s\tremaining: 5m 5s\n",
            "142:\tlearn: 0.0846829\ttotal: 50.9s\tremaining: 5m 5s\n",
            "143:\tlearn: 0.0845805\ttotal: 51.3s\tremaining: 5m 4s\n",
            "144:\tlearn: 0.0844926\ttotal: 51.7s\tremaining: 5m 4s\n",
            "145:\tlearn: 0.0843972\ttotal: 52s\tremaining: 5m 4s\n",
            "146:\tlearn: 0.0843221\ttotal: 52.4s\tremaining: 5m 3s\n",
            "147:\tlearn: 0.0842765\ttotal: 52.7s\tremaining: 5m 3s\n",
            "148:\tlearn: 0.0842191\ttotal: 53s\tremaining: 5m 2s\n",
            "149:\tlearn: 0.0841894\ttotal: 53.4s\tremaining: 5m 2s\n",
            "150:\tlearn: 0.0841558\ttotal: 53.7s\tremaining: 5m 1s\n",
            "151:\tlearn: 0.0841166\ttotal: 54s\tremaining: 5m 1s\n",
            "152:\tlearn: 0.0840336\ttotal: 54.4s\tremaining: 5m 1s\n",
            "153:\tlearn: 0.0839458\ttotal: 54.8s\tremaining: 5m\n",
            "154:\tlearn: 0.0838971\ttotal: 55.1s\tremaining: 5m\n",
            "155:\tlearn: 0.0837759\ttotal: 55.5s\tremaining: 5m\n",
            "156:\tlearn: 0.0837179\ttotal: 55.9s\tremaining: 5m\n",
            "157:\tlearn: 0.0836542\ttotal: 56.3s\tremaining: 4m 59s\n",
            "158:\tlearn: 0.0835791\ttotal: 56.6s\tremaining: 4m 59s\n",
            "159:\tlearn: 0.0835405\ttotal: 57s\tremaining: 4m 59s\n",
            "160:\tlearn: 0.0834968\ttotal: 57.4s\tremaining: 4m 58s\n",
            "161:\tlearn: 0.0834297\ttotal: 57.8s\tremaining: 4m 58s\n",
            "162:\tlearn: 0.0834051\ttotal: 58.1s\tremaining: 4m 58s\n",
            "163:\tlearn: 0.0833005\ttotal: 58.5s\tremaining: 4m 58s\n",
            "164:\tlearn: 0.0832595\ttotal: 58.9s\tremaining: 4m 58s\n",
            "165:\tlearn: 0.0832069\ttotal: 59.3s\tremaining: 4m 57s\n",
            "166:\tlearn: 0.0831303\ttotal: 59.7s\tremaining: 4m 57s\n",
            "167:\tlearn: 0.0830942\ttotal: 1m\tremaining: 4m 57s\n",
            "168:\tlearn: 0.0830369\ttotal: 1m\tremaining: 4m 56s\n",
            "169:\tlearn: 0.0829385\ttotal: 1m\tremaining: 4m 56s\n",
            "170:\tlearn: 0.0828659\ttotal: 1m 1s\tremaining: 4m 55s\n",
            "171:\tlearn: 0.0828082\ttotal: 1m 1s\tremaining: 4m 55s\n",
            "172:\tlearn: 0.0827292\ttotal: 1m 1s\tremaining: 4m 55s\n",
            "173:\tlearn: 0.0826525\ttotal: 1m 2s\tremaining: 4m 54s\n",
            "174:\tlearn: 0.0825916\ttotal: 1m 2s\tremaining: 4m 54s\n",
            "175:\tlearn: 0.0825191\ttotal: 1m 2s\tremaining: 4m 54s\n",
            "176:\tlearn: 0.0824362\ttotal: 1m 3s\tremaining: 4m 54s\n",
            "177:\tlearn: 0.0823503\ttotal: 1m 3s\tremaining: 4m 53s\n",
            "178:\tlearn: 0.0822947\ttotal: 1m 4s\tremaining: 4m 53s\n",
            "179:\tlearn: 0.0822276\ttotal: 1m 4s\tremaining: 4m 53s\n",
            "180:\tlearn: 0.0821644\ttotal: 1m 4s\tremaining: 4m 53s\n",
            "181:\tlearn: 0.0821470\ttotal: 1m 5s\tremaining: 4m 52s\n",
            "182:\tlearn: 0.0820716\ttotal: 1m 5s\tremaining: 4m 52s\n",
            "183:\tlearn: 0.0820529\ttotal: 1m 5s\tremaining: 4m 51s\n",
            "184:\tlearn: 0.0819814\ttotal: 1m 6s\tremaining: 4m 51s\n",
            "185:\tlearn: 0.0819504\ttotal: 1m 6s\tremaining: 4m 51s\n",
            "186:\tlearn: 0.0819171\ttotal: 1m 6s\tremaining: 4m 50s\n",
            "187:\tlearn: 0.0818676\ttotal: 1m 7s\tremaining: 4m 50s\n",
            "188:\tlearn: 0.0818206\ttotal: 1m 7s\tremaining: 4m 49s\n",
            "189:\tlearn: 0.0817741\ttotal: 1m 7s\tremaining: 4m 49s\n",
            "190:\tlearn: 0.0816879\ttotal: 1m 8s\tremaining: 4m 49s\n",
            "191:\tlearn: 0.0816430\ttotal: 1m 8s\tremaining: 4m 48s\n",
            "192:\tlearn: 0.0816011\ttotal: 1m 8s\tremaining: 4m 48s\n",
            "193:\tlearn: 0.0815504\ttotal: 1m 9s\tremaining: 4m 47s\n",
            "194:\tlearn: 0.0814974\ttotal: 1m 9s\tremaining: 4m 47s\n",
            "195:\tlearn: 0.0814631\ttotal: 1m 9s\tremaining: 4m 46s\n",
            "196:\tlearn: 0.0813651\ttotal: 1m 10s\tremaining: 4m 46s\n",
            "197:\tlearn: 0.0813260\ttotal: 1m 10s\tremaining: 4m 46s\n",
            "198:\tlearn: 0.0812727\ttotal: 1m 10s\tremaining: 4m 45s\n",
            "199:\tlearn: 0.0812107\ttotal: 1m 11s\tremaining: 4m 45s\n",
            "200:\tlearn: 0.0811562\ttotal: 1m 11s\tremaining: 4m 44s\n",
            "201:\tlearn: 0.0810827\ttotal: 1m 12s\tremaining: 4m 44s\n",
            "202:\tlearn: 0.0810275\ttotal: 1m 12s\tremaining: 4m 44s\n",
            "203:\tlearn: 0.0809869\ttotal: 1m 12s\tremaining: 4m 43s\n",
            "204:\tlearn: 0.0809476\ttotal: 1m 12s\tremaining: 4m 43s\n",
            "205:\tlearn: 0.0808902\ttotal: 1m 13s\tremaining: 4m 42s\n",
            "206:\tlearn: 0.0808301\ttotal: 1m 13s\tremaining: 4m 42s\n",
            "207:\tlearn: 0.0807622\ttotal: 1m 14s\tremaining: 4m 42s\n",
            "208:\tlearn: 0.0807268\ttotal: 1m 14s\tremaining: 4m 41s\n",
            "209:\tlearn: 0.0806806\ttotal: 1m 14s\tremaining: 4m 41s\n",
            "210:\tlearn: 0.0806467\ttotal: 1m 15s\tremaining: 4m 40s\n",
            "211:\tlearn: 0.0805829\ttotal: 1m 15s\tremaining: 4m 40s\n",
            "212:\tlearn: 0.0805409\ttotal: 1m 15s\tremaining: 4m 40s\n",
            "213:\tlearn: 0.0804955\ttotal: 1m 16s\tremaining: 4m 40s\n",
            "214:\tlearn: 0.0804502\ttotal: 1m 16s\tremaining: 4m 39s\n",
            "215:\tlearn: 0.0803783\ttotal: 1m 16s\tremaining: 4m 39s\n",
            "216:\tlearn: 0.0803497\ttotal: 1m 17s\tremaining: 4m 38s\n",
            "217:\tlearn: 0.0803031\ttotal: 1m 17s\tremaining: 4m 38s\n",
            "218:\tlearn: 0.0802618\ttotal: 1m 17s\tremaining: 4m 37s\n",
            "219:\tlearn: 0.0802299\ttotal: 1m 18s\tremaining: 4m 37s\n",
            "220:\tlearn: 0.0801787\ttotal: 1m 18s\tremaining: 4m 36s\n",
            "221:\tlearn: 0.0801126\ttotal: 1m 18s\tremaining: 4m 36s\n",
            "222:\tlearn: 0.0800766\ttotal: 1m 19s\tremaining: 4m 35s\n",
            "223:\tlearn: 0.0800336\ttotal: 1m 19s\tremaining: 4m 35s\n",
            "224:\tlearn: 0.0799817\ttotal: 1m 19s\tremaining: 4m 34s\n",
            "225:\tlearn: 0.0799223\ttotal: 1m 20s\tremaining: 4m 34s\n",
            "226:\tlearn: 0.0798767\ttotal: 1m 20s\tremaining: 4m 34s\n",
            "227:\tlearn: 0.0798393\ttotal: 1m 20s\tremaining: 4m 34s\n",
            "228:\tlearn: 0.0797962\ttotal: 1m 21s\tremaining: 4m 33s\n",
            "229:\tlearn: 0.0797367\ttotal: 1m 21s\tremaining: 4m 33s\n",
            "230:\tlearn: 0.0796549\ttotal: 1m 21s\tremaining: 4m 32s\n",
            "231:\tlearn: 0.0796422\ttotal: 1m 22s\tremaining: 4m 32s\n",
            "232:\tlearn: 0.0796058\ttotal: 1m 22s\tremaining: 4m 31s\n",
            "233:\tlearn: 0.0795642\ttotal: 1m 22s\tremaining: 4m 31s\n",
            "234:\tlearn: 0.0794967\ttotal: 1m 23s\tremaining: 4m 30s\n",
            "235:\tlearn: 0.0794519\ttotal: 1m 23s\tremaining: 4m 30s\n",
            "236:\tlearn: 0.0794224\ttotal: 1m 23s\tremaining: 4m 30s\n",
            "237:\tlearn: 0.0793398\ttotal: 1m 24s\tremaining: 4m 29s\n",
            "238:\tlearn: 0.0792837\ttotal: 1m 24s\tremaining: 4m 29s\n",
            "239:\tlearn: 0.0792205\ttotal: 1m 24s\tremaining: 4m 28s\n",
            "240:\tlearn: 0.0791538\ttotal: 1m 25s\tremaining: 4m 28s\n",
            "241:\tlearn: 0.0791253\ttotal: 1m 25s\tremaining: 4m 28s\n",
            "242:\tlearn: 0.0790608\ttotal: 1m 25s\tremaining: 4m 27s\n",
            "243:\tlearn: 0.0790110\ttotal: 1m 26s\tremaining: 4m 27s\n",
            "244:\tlearn: 0.0789783\ttotal: 1m 26s\tremaining: 4m 26s\n",
            "245:\tlearn: 0.0789365\ttotal: 1m 26s\tremaining: 4m 26s\n",
            "246:\tlearn: 0.0789055\ttotal: 1m 27s\tremaining: 4m 26s\n",
            "247:\tlearn: 0.0788899\ttotal: 1m 27s\tremaining: 4m 25s\n",
            "248:\tlearn: 0.0788635\ttotal: 1m 27s\tremaining: 4m 25s\n",
            "249:\tlearn: 0.0788309\ttotal: 1m 28s\tremaining: 4m 24s\n",
            "250:\tlearn: 0.0787993\ttotal: 1m 28s\tremaining: 4m 24s\n",
            "251:\tlearn: 0.0787461\ttotal: 1m 28s\tremaining: 4m 23s\n",
            "252:\tlearn: 0.0786791\ttotal: 1m 29s\tremaining: 4m 23s\n",
            "253:\tlearn: 0.0786396\ttotal: 1m 29s\tremaining: 4m 22s\n",
            "254:\tlearn: 0.0786231\ttotal: 1m 29s\tremaining: 4m 22s\n",
            "255:\tlearn: 0.0786003\ttotal: 1m 30s\tremaining: 4m 21s\n",
            "256:\tlearn: 0.0785631\ttotal: 1m 30s\tremaining: 4m 21s\n",
            "257:\tlearn: 0.0784879\ttotal: 1m 30s\tremaining: 4m 21s\n",
            "258:\tlearn: 0.0784375\ttotal: 1m 31s\tremaining: 4m 20s\n",
            "259:\tlearn: 0.0783336\ttotal: 1m 31s\tremaining: 4m 20s\n",
            "260:\tlearn: 0.0783049\ttotal: 1m 31s\tremaining: 4m 20s\n",
            "261:\tlearn: 0.0782192\ttotal: 1m 32s\tremaining: 4m 20s\n",
            "262:\tlearn: 0.0781771\ttotal: 1m 32s\tremaining: 4m 19s\n",
            "263:\tlearn: 0.0781548\ttotal: 1m 33s\tremaining: 4m 19s\n",
            "264:\tlearn: 0.0781189\ttotal: 1m 33s\tremaining: 4m 19s\n",
            "265:\tlearn: 0.0780729\ttotal: 1m 33s\tremaining: 4m 18s\n",
            "266:\tlearn: 0.0780501\ttotal: 1m 34s\tremaining: 4m 18s\n",
            "267:\tlearn: 0.0779753\ttotal: 1m 34s\tremaining: 4m 17s\n",
            "268:\tlearn: 0.0779085\ttotal: 1m 34s\tremaining: 4m 17s\n",
            "269:\tlearn: 0.0778736\ttotal: 1m 35s\tremaining: 4m 17s\n",
            "270:\tlearn: 0.0778355\ttotal: 1m 35s\tremaining: 4m 17s\n",
            "271:\tlearn: 0.0777536\ttotal: 1m 35s\tremaining: 4m 16s\n",
            "272:\tlearn: 0.0777262\ttotal: 1m 36s\tremaining: 4m 16s\n",
            "273:\tlearn: 0.0777063\ttotal: 1m 36s\tremaining: 4m 15s\n",
            "274:\tlearn: 0.0776431\ttotal: 1m 36s\tremaining: 4m 15s\n",
            "275:\tlearn: 0.0776354\ttotal: 1m 37s\tremaining: 4m 14s\n",
            "276:\tlearn: 0.0775907\ttotal: 1m 37s\tremaining: 4m 14s\n",
            "277:\tlearn: 0.0775515\ttotal: 1m 37s\tremaining: 4m 14s\n",
            "278:\tlearn: 0.0775068\ttotal: 1m 38s\tremaining: 4m 13s\n",
            "279:\tlearn: 0.0774647\ttotal: 1m 38s\tremaining: 4m 13s\n",
            "280:\tlearn: 0.0774178\ttotal: 1m 38s\tremaining: 4m 12s\n",
            "281:\tlearn: 0.0773790\ttotal: 1m 39s\tremaining: 4m 12s\n",
            "282:\tlearn: 0.0773467\ttotal: 1m 39s\tremaining: 4m 12s\n",
            "283:\tlearn: 0.0773125\ttotal: 1m 39s\tremaining: 4m 11s\n",
            "284:\tlearn: 0.0772800\ttotal: 1m 40s\tremaining: 4m 11s\n",
            "285:\tlearn: 0.0772206\ttotal: 1m 40s\tremaining: 4m 11s\n",
            "286:\tlearn: 0.0771567\ttotal: 1m 41s\tremaining: 4m 10s\n",
            "287:\tlearn: 0.0771146\ttotal: 1m 41s\tremaining: 4m 10s\n",
            "288:\tlearn: 0.0770806\ttotal: 1m 41s\tremaining: 4m 9s\n",
            "289:\tlearn: 0.0770387\ttotal: 1m 41s\tremaining: 4m 9s\n",
            "290:\tlearn: 0.0770164\ttotal: 1m 42s\tremaining: 4m 9s\n",
            "291:\tlearn: 0.0769623\ttotal: 1m 42s\tremaining: 4m 8s\n",
            "292:\tlearn: 0.0769435\ttotal: 1m 42s\tremaining: 4m 8s\n",
            "293:\tlearn: 0.0768658\ttotal: 1m 43s\tremaining: 4m 7s\n",
            "294:\tlearn: 0.0768018\ttotal: 1m 43s\tremaining: 4m 7s\n",
            "295:\tlearn: 0.0767510\ttotal: 1m 43s\tremaining: 4m 7s\n",
            "296:\tlearn: 0.0767130\ttotal: 1m 44s\tremaining: 4m 6s\n",
            "297:\tlearn: 0.0766868\ttotal: 1m 44s\tremaining: 4m 6s\n",
            "298:\tlearn: 0.0766515\ttotal: 1m 44s\tremaining: 4m 5s\n",
            "299:\tlearn: 0.0766079\ttotal: 1m 45s\tremaining: 4m 5s\n",
            "300:\tlearn: 0.0765914\ttotal: 1m 45s\tremaining: 4m 4s\n",
            "301:\tlearn: 0.0765345\ttotal: 1m 45s\tremaining: 4m 4s\n",
            "302:\tlearn: 0.0764717\ttotal: 1m 46s\tremaining: 4m 4s\n",
            "303:\tlearn: 0.0764609\ttotal: 1m 46s\tremaining: 4m 3s\n",
            "304:\tlearn: 0.0764210\ttotal: 1m 46s\tremaining: 4m 3s\n",
            "305:\tlearn: 0.0763775\ttotal: 1m 47s\tremaining: 4m 3s\n",
            "306:\tlearn: 0.0763101\ttotal: 1m 47s\tremaining: 4m 2s\n",
            "307:\tlearn: 0.0762530\ttotal: 1m 47s\tremaining: 4m 2s\n",
            "308:\tlearn: 0.0761971\ttotal: 1m 48s\tremaining: 4m 2s\n",
            "309:\tlearn: 0.0761919\ttotal: 1m 48s\tremaining: 4m 1s\n",
            "310:\tlearn: 0.0761471\ttotal: 1m 48s\tremaining: 4m 1s\n",
            "311:\tlearn: 0.0761059\ttotal: 1m 49s\tremaining: 4m 1s\n",
            "312:\tlearn: 0.0760583\ttotal: 1m 49s\tremaining: 4m\n",
            "313:\tlearn: 0.0760121\ttotal: 1m 50s\tremaining: 4m\n",
            "314:\tlearn: 0.0759627\ttotal: 1m 50s\tremaining: 4m\n",
            "315:\tlearn: 0.0759339\ttotal: 1m 50s\tremaining: 3m 59s\n",
            "316:\tlearn: 0.0758961\ttotal: 1m 51s\tremaining: 3m 59s\n",
            "317:\tlearn: 0.0758642\ttotal: 1m 51s\tremaining: 3m 58s\n",
            "318:\tlearn: 0.0758152\ttotal: 1m 51s\tremaining: 3m 58s\n",
            "319:\tlearn: 0.0757849\ttotal: 1m 52s\tremaining: 3m 58s\n",
            "320:\tlearn: 0.0757547\ttotal: 1m 52s\tremaining: 3m 57s\n",
            "321:\tlearn: 0.0757263\ttotal: 1m 52s\tremaining: 3m 57s\n",
            "322:\tlearn: 0.0756724\ttotal: 1m 53s\tremaining: 3m 57s\n",
            "323:\tlearn: 0.0756074\ttotal: 1m 53s\tremaining: 3m 56s\n",
            "324:\tlearn: 0.0755868\ttotal: 1m 53s\tremaining: 3m 56s\n",
            "325:\tlearn: 0.0755304\ttotal: 1m 54s\tremaining: 3m 56s\n",
            "326:\tlearn: 0.0755055\ttotal: 1m 54s\tremaining: 3m 55s\n",
            "327:\tlearn: 0.0754594\ttotal: 1m 54s\tremaining: 3m 55s\n",
            "328:\tlearn: 0.0754217\ttotal: 1m 55s\tremaining: 3m 55s\n",
            "329:\tlearn: 0.0754001\ttotal: 1m 55s\tremaining: 3m 54s\n",
            "330:\tlearn: 0.0753694\ttotal: 1m 55s\tremaining: 3m 54s\n",
            "331:\tlearn: 0.0753096\ttotal: 1m 56s\tremaining: 3m 54s\n",
            "332:\tlearn: 0.0752894\ttotal: 1m 56s\tremaining: 3m 53s\n",
            "333:\tlearn: 0.0752351\ttotal: 1m 57s\tremaining: 3m 53s\n",
            "334:\tlearn: 0.0752104\ttotal: 1m 57s\tremaining: 3m 53s\n",
            "335:\tlearn: 0.0751539\ttotal: 1m 57s\tremaining: 3m 52s\n",
            "336:\tlearn: 0.0751242\ttotal: 1m 58s\tremaining: 3m 52s\n",
            "337:\tlearn: 0.0750778\ttotal: 1m 58s\tremaining: 3m 52s\n",
            "338:\tlearn: 0.0750167\ttotal: 1m 58s\tremaining: 3m 51s\n",
            "339:\tlearn: 0.0749706\ttotal: 1m 59s\tremaining: 3m 51s\n",
            "340:\tlearn: 0.0749206\ttotal: 1m 59s\tremaining: 3m 51s\n",
            "341:\tlearn: 0.0748852\ttotal: 1m 59s\tremaining: 3m 50s\n",
            "342:\tlearn: 0.0748709\ttotal: 2m\tremaining: 3m 50s\n",
            "343:\tlearn: 0.0748498\ttotal: 2m\tremaining: 3m 50s\n",
            "344:\tlearn: 0.0747964\ttotal: 2m 1s\tremaining: 3m 49s\n",
            "345:\tlearn: 0.0747702\ttotal: 2m 1s\tremaining: 3m 49s\n",
            "346:\tlearn: 0.0747372\ttotal: 2m 1s\tremaining: 3m 49s\n",
            "347:\tlearn: 0.0747001\ttotal: 2m 2s\tremaining: 3m 48s\n",
            "348:\tlearn: 0.0746665\ttotal: 2m 2s\tremaining: 3m 48s\n",
            "349:\tlearn: 0.0746087\ttotal: 2m 2s\tremaining: 3m 48s\n",
            "350:\tlearn: 0.0745911\ttotal: 2m 3s\tremaining: 3m 47s\n",
            "351:\tlearn: 0.0745327\ttotal: 2m 3s\tremaining: 3m 47s\n",
            "352:\tlearn: 0.0744896\ttotal: 2m 4s\tremaining: 3m 47s\n",
            "353:\tlearn: 0.0744241\ttotal: 2m 4s\tremaining: 3m 47s\n",
            "354:\tlearn: 0.0744060\ttotal: 2m 4s\tremaining: 3m 46s\n",
            "355:\tlearn: 0.0743628\ttotal: 2m 5s\tremaining: 3m 46s\n",
            "356:\tlearn: 0.0743231\ttotal: 2m 5s\tremaining: 3m 46s\n",
            "357:\tlearn: 0.0742842\ttotal: 2m 5s\tremaining: 3m 45s\n",
            "358:\tlearn: 0.0742430\ttotal: 2m 6s\tremaining: 3m 45s\n",
            "359:\tlearn: 0.0742010\ttotal: 2m 6s\tremaining: 3m 44s\n",
            "360:\tlearn: 0.0741889\ttotal: 2m 6s\tremaining: 3m 44s\n",
            "361:\tlearn: 0.0741578\ttotal: 2m 7s\tremaining: 3m 44s\n",
            "362:\tlearn: 0.0741304\ttotal: 2m 7s\tremaining: 3m 43s\n",
            "363:\tlearn: 0.0741214\ttotal: 2m 7s\tremaining: 3m 43s\n",
            "364:\tlearn: 0.0741055\ttotal: 2m 8s\tremaining: 3m 42s\n",
            "365:\tlearn: 0.0740739\ttotal: 2m 8s\tremaining: 3m 42s\n",
            "366:\tlearn: 0.0740314\ttotal: 2m 8s\tremaining: 3m 42s\n",
            "367:\tlearn: 0.0739574\ttotal: 2m 9s\tremaining: 3m 41s\n",
            "368:\tlearn: 0.0739393\ttotal: 2m 9s\tremaining: 3m 41s\n",
            "369:\tlearn: 0.0739107\ttotal: 2m 9s\tremaining: 3m 40s\n",
            "370:\tlearn: 0.0738778\ttotal: 2m 10s\tremaining: 3m 40s\n",
            "371:\tlearn: 0.0738409\ttotal: 2m 10s\tremaining: 3m 40s\n",
            "372:\tlearn: 0.0738088\ttotal: 2m 10s\tremaining: 3m 39s\n",
            "373:\tlearn: 0.0737759\ttotal: 2m 11s\tremaining: 3m 39s\n",
            "374:\tlearn: 0.0737520\ttotal: 2m 11s\tremaining: 3m 39s\n",
            "375:\tlearn: 0.0737220\ttotal: 2m 11s\tremaining: 3m 38s\n",
            "376:\tlearn: 0.0736895\ttotal: 2m 12s\tremaining: 3m 38s\n",
            "377:\tlearn: 0.0736599\ttotal: 2m 12s\tremaining: 3m 37s\n",
            "378:\tlearn: 0.0736285\ttotal: 2m 12s\tremaining: 3m 37s\n",
            "379:\tlearn: 0.0736020\ttotal: 2m 13s\tremaining: 3m 37s\n",
            "380:\tlearn: 0.0735672\ttotal: 2m 13s\tremaining: 3m 37s\n",
            "381:\tlearn: 0.0735549\ttotal: 2m 13s\tremaining: 3m 36s\n",
            "382:\tlearn: 0.0735245\ttotal: 2m 14s\tremaining: 3m 36s\n",
            "383:\tlearn: 0.0734787\ttotal: 2m 14s\tremaining: 3m 35s\n",
            "384:\tlearn: 0.0734467\ttotal: 2m 14s\tremaining: 3m 35s\n",
            "385:\tlearn: 0.0734247\ttotal: 2m 15s\tremaining: 3m 35s\n",
            "386:\tlearn: 0.0733715\ttotal: 2m 15s\tremaining: 3m 34s\n",
            "387:\tlearn: 0.0733299\ttotal: 2m 15s\tremaining: 3m 34s\n",
            "388:\tlearn: 0.0732908\ttotal: 2m 16s\tremaining: 3m 33s\n",
            "389:\tlearn: 0.0732589\ttotal: 2m 16s\tremaining: 3m 33s\n",
            "390:\tlearn: 0.0732337\ttotal: 2m 16s\tremaining: 3m 33s\n",
            "391:\tlearn: 0.0731902\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "392:\tlearn: 0.0731456\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "393:\tlearn: 0.0731197\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "394:\tlearn: 0.0730843\ttotal: 2m 18s\tremaining: 3m 31s\n",
            "395:\tlearn: 0.0730483\ttotal: 2m 18s\tremaining: 3m 31s\n",
            "396:\tlearn: 0.0730051\ttotal: 2m 19s\tremaining: 3m 31s\n",
            "397:\tlearn: 0.0729943\ttotal: 2m 19s\tremaining: 3m 30s\n",
            "398:\tlearn: 0.0729781\ttotal: 2m 19s\tremaining: 3m 30s\n",
            "399:\tlearn: 0.0729413\ttotal: 2m 20s\tremaining: 3m 30s\n",
            "400:\tlearn: 0.0729304\ttotal: 2m 20s\tremaining: 3m 29s\n",
            "401:\tlearn: 0.0728829\ttotal: 2m 20s\tremaining: 3m 29s\n",
            "402:\tlearn: 0.0728507\ttotal: 2m 21s\tremaining: 3m 29s\n",
            "403:\tlearn: 0.0728005\ttotal: 2m 21s\tremaining: 3m 28s\n",
            "404:\tlearn: 0.0727654\ttotal: 2m 21s\tremaining: 3m 28s\n",
            "405:\tlearn: 0.0727431\ttotal: 2m 22s\tremaining: 3m 28s\n",
            "406:\tlearn: 0.0726975\ttotal: 2m 22s\tremaining: 3m 27s\n",
            "407:\tlearn: 0.0726501\ttotal: 2m 22s\tremaining: 3m 27s\n",
            "408:\tlearn: 0.0725974\ttotal: 2m 23s\tremaining: 3m 27s\n",
            "409:\tlearn: 0.0725802\ttotal: 2m 23s\tremaining: 3m 26s\n",
            "410:\tlearn: 0.0725640\ttotal: 2m 24s\tremaining: 3m 26s\n",
            "411:\tlearn: 0.0725353\ttotal: 2m 24s\tremaining: 3m 26s\n",
            "412:\tlearn: 0.0725223\ttotal: 2m 24s\tremaining: 3m 25s\n",
            "413:\tlearn: 0.0724965\ttotal: 2m 25s\tremaining: 3m 25s\n",
            "414:\tlearn: 0.0724852\ttotal: 2m 25s\tremaining: 3m 24s\n",
            "415:\tlearn: 0.0724491\ttotal: 2m 25s\tremaining: 3m 24s\n",
            "416:\tlearn: 0.0724141\ttotal: 2m 26s\tremaining: 3m 24s\n",
            "417:\tlearn: 0.0723723\ttotal: 2m 26s\tremaining: 3m 23s\n",
            "418:\tlearn: 0.0723018\ttotal: 2m 26s\tremaining: 3m 23s\n",
            "419:\tlearn: 0.0722740\ttotal: 2m 27s\tremaining: 3m 23s\n",
            "420:\tlearn: 0.0722579\ttotal: 2m 27s\tremaining: 3m 22s\n",
            "421:\tlearn: 0.0722317\ttotal: 2m 27s\tremaining: 3m 22s\n",
            "422:\tlearn: 0.0721916\ttotal: 2m 28s\tremaining: 3m 22s\n",
            "423:\tlearn: 0.0720912\ttotal: 2m 28s\tremaining: 3m 21s\n",
            "424:\tlearn: 0.0720647\ttotal: 2m 28s\tremaining: 3m 21s\n",
            "425:\tlearn: 0.0720287\ttotal: 2m 29s\tremaining: 3m 21s\n",
            "426:\tlearn: 0.0720010\ttotal: 2m 29s\tremaining: 3m 20s\n",
            "427:\tlearn: 0.0719673\ttotal: 2m 29s\tremaining: 3m 20s\n",
            "428:\tlearn: 0.0719370\ttotal: 2m 30s\tremaining: 3m 19s\n",
            "429:\tlearn: 0.0719168\ttotal: 2m 30s\tremaining: 3m 19s\n",
            "430:\tlearn: 0.0718957\ttotal: 2m 30s\tremaining: 3m 19s\n",
            "431:\tlearn: 0.0718576\ttotal: 2m 31s\tremaining: 3m 18s\n",
            "432:\tlearn: 0.0718432\ttotal: 2m 31s\tremaining: 3m 18s\n",
            "433:\tlearn: 0.0717973\ttotal: 2m 31s\tremaining: 3m 17s\n",
            "434:\tlearn: 0.0717655\ttotal: 2m 32s\tremaining: 3m 17s\n",
            "435:\tlearn: 0.0717490\ttotal: 2m 32s\tremaining: 3m 17s\n",
            "436:\tlearn: 0.0716941\ttotal: 2m 32s\tremaining: 3m 16s\n",
            "437:\tlearn: 0.0716679\ttotal: 2m 33s\tremaining: 3m 16s\n",
            "438:\tlearn: 0.0716403\ttotal: 2m 33s\tremaining: 3m 16s\n",
            "439:\tlearn: 0.0715860\ttotal: 2m 33s\tremaining: 3m 15s\n",
            "440:\tlearn: 0.0715518\ttotal: 2m 34s\tremaining: 3m 15s\n",
            "441:\tlearn: 0.0715279\ttotal: 2m 34s\tremaining: 3m 15s\n",
            "442:\tlearn: 0.0714941\ttotal: 2m 34s\tremaining: 3m 14s\n",
            "443:\tlearn: 0.0714696\ttotal: 2m 35s\tremaining: 3m 14s\n",
            "444:\tlearn: 0.0714332\ttotal: 2m 35s\tremaining: 3m 14s\n",
            "445:\tlearn: 0.0714147\ttotal: 2m 36s\tremaining: 3m 13s\n",
            "446:\tlearn: 0.0713664\ttotal: 2m 36s\tremaining: 3m 13s\n",
            "447:\tlearn: 0.0713427\ttotal: 2m 36s\tremaining: 3m 13s\n",
            "448:\tlearn: 0.0713000\ttotal: 2m 37s\tremaining: 3m 12s\n",
            "449:\tlearn: 0.0712863\ttotal: 2m 37s\tremaining: 3m 12s\n",
            "450:\tlearn: 0.0712274\ttotal: 2m 37s\tremaining: 3m 11s\n",
            "451:\tlearn: 0.0712094\ttotal: 2m 38s\tremaining: 3m 11s\n",
            "452:\tlearn: 0.0711809\ttotal: 2m 38s\tremaining: 3m 11s\n",
            "453:\tlearn: 0.0711639\ttotal: 2m 38s\tremaining: 3m 10s\n",
            "454:\tlearn: 0.0711481\ttotal: 2m 39s\tremaining: 3m 10s\n",
            "455:\tlearn: 0.0711152\ttotal: 2m 39s\tremaining: 3m 10s\n",
            "456:\tlearn: 0.0710928\ttotal: 2m 39s\tremaining: 3m 9s\n",
            "457:\tlearn: 0.0710780\ttotal: 2m 39s\tremaining: 3m 9s\n",
            "458:\tlearn: 0.0710571\ttotal: 2m 40s\tremaining: 3m 8s\n",
            "459:\tlearn: 0.0710314\ttotal: 2m 40s\tremaining: 3m 8s\n",
            "460:\tlearn: 0.0710074\ttotal: 2m 41s\tremaining: 3m 8s\n",
            "461:\tlearn: 0.0709848\ttotal: 2m 41s\tremaining: 3m 7s\n",
            "462:\tlearn: 0.0709655\ttotal: 2m 41s\tremaining: 3m 7s\n",
            "463:\tlearn: 0.0709401\ttotal: 2m 41s\tremaining: 3m 7s\n",
            "464:\tlearn: 0.0709311\ttotal: 2m 42s\tremaining: 3m 6s\n",
            "465:\tlearn: 0.0709058\ttotal: 2m 42s\tremaining: 3m 6s\n",
            "466:\tlearn: 0.0708972\ttotal: 2m 42s\tremaining: 3m 5s\n",
            "467:\tlearn: 0.0708518\ttotal: 2m 43s\tremaining: 3m 5s\n",
            "468:\tlearn: 0.0708294\ttotal: 2m 43s\tremaining: 3m 5s\n",
            "469:\tlearn: 0.0708040\ttotal: 2m 44s\tremaining: 3m 5s\n",
            "470:\tlearn: 0.0707962\ttotal: 2m 44s\tremaining: 3m 4s\n",
            "471:\tlearn: 0.0707913\ttotal: 2m 44s\tremaining: 3m 4s\n",
            "472:\tlearn: 0.0707602\ttotal: 2m 45s\tremaining: 3m 3s\n",
            "473:\tlearn: 0.0707419\ttotal: 2m 45s\tremaining: 3m 3s\n",
            "474:\tlearn: 0.0706996\ttotal: 2m 45s\tremaining: 3m 3s\n",
            "475:\tlearn: 0.0706419\ttotal: 2m 46s\tremaining: 3m 2s\n",
            "476:\tlearn: 0.0706110\ttotal: 2m 46s\tremaining: 3m 2s\n",
            "477:\tlearn: 0.0706060\ttotal: 2m 46s\tremaining: 3m 2s\n",
            "478:\tlearn: 0.0705760\ttotal: 2m 47s\tremaining: 3m 1s\n",
            "479:\tlearn: 0.0705642\ttotal: 2m 47s\tremaining: 3m 1s\n",
            "480:\tlearn: 0.0705296\ttotal: 2m 47s\tremaining: 3m 1s\n",
            "481:\tlearn: 0.0705097\ttotal: 2m 48s\tremaining: 3m\n",
            "482:\tlearn: 0.0704787\ttotal: 2m 48s\tremaining: 3m\n",
            "483:\tlearn: 0.0704263\ttotal: 2m 49s\tremaining: 3m\n",
            "484:\tlearn: 0.0704176\ttotal: 2m 49s\tremaining: 2m 59s\n",
            "485:\tlearn: 0.0703968\ttotal: 2m 49s\tremaining: 2m 59s\n",
            "486:\tlearn: 0.0703720\ttotal: 2m 50s\tremaining: 2m 59s\n",
            "487:\tlearn: 0.0703315\ttotal: 2m 50s\tremaining: 2m 58s\n",
            "488:\tlearn: 0.0703172\ttotal: 2m 50s\tremaining: 2m 58s\n",
            "489:\tlearn: 0.0702849\ttotal: 2m 51s\tremaining: 2m 58s\n",
            "490:\tlearn: 0.0702677\ttotal: 2m 51s\tremaining: 2m 57s\n",
            "491:\tlearn: 0.0702344\ttotal: 2m 51s\tremaining: 2m 57s\n",
            "492:\tlearn: 0.0702238\ttotal: 2m 51s\tremaining: 2m 56s\n",
            "493:\tlearn: 0.0701736\ttotal: 2m 52s\tremaining: 2m 56s\n",
            "494:\tlearn: 0.0701635\ttotal: 2m 52s\tremaining: 2m 56s\n",
            "495:\tlearn: 0.0701511\ttotal: 2m 53s\tremaining: 2m 55s\n",
            "496:\tlearn: 0.0701255\ttotal: 2m 53s\tremaining: 2m 55s\n",
            "497:\tlearn: 0.0701103\ttotal: 2m 53s\tremaining: 2m 55s\n",
            "498:\tlearn: 0.0700702\ttotal: 2m 54s\tremaining: 2m 54s\n",
            "499:\tlearn: 0.0700173\ttotal: 2m 54s\tremaining: 2m 54s\n",
            "500:\tlearn: 0.0699993\ttotal: 2m 54s\tremaining: 2m 54s\n",
            "501:\tlearn: 0.0699500\ttotal: 2m 55s\tremaining: 2m 53s\n",
            "502:\tlearn: 0.0699154\ttotal: 2m 55s\tremaining: 2m 53s\n",
            "503:\tlearn: 0.0698953\ttotal: 2m 55s\tremaining: 2m 53s\n",
            "504:\tlearn: 0.0698844\ttotal: 2m 56s\tremaining: 2m 52s\n",
            "505:\tlearn: 0.0698637\ttotal: 2m 56s\tremaining: 2m 52s\n",
            "506:\tlearn: 0.0698302\ttotal: 2m 56s\tremaining: 2m 51s\n",
            "507:\tlearn: 0.0698123\ttotal: 2m 57s\tremaining: 2m 51s\n",
            "508:\tlearn: 0.0697704\ttotal: 2m 57s\tremaining: 2m 51s\n",
            "509:\tlearn: 0.0697310\ttotal: 2m 57s\tremaining: 2m 50s\n",
            "510:\tlearn: 0.0697045\ttotal: 2m 58s\tremaining: 2m 50s\n",
            "511:\tlearn: 0.0696701\ttotal: 2m 58s\tremaining: 2m 50s\n",
            "512:\tlearn: 0.0696250\ttotal: 2m 58s\tremaining: 2m 49s\n",
            "513:\tlearn: 0.0696004\ttotal: 2m 59s\tremaining: 2m 49s\n",
            "514:\tlearn: 0.0695638\ttotal: 2m 59s\tremaining: 2m 49s\n",
            "515:\tlearn: 0.0695592\ttotal: 2m 59s\tremaining: 2m 48s\n",
            "516:\tlearn: 0.0695341\ttotal: 3m\tremaining: 2m 48s\n",
            "517:\tlearn: 0.0695036\ttotal: 3m\tremaining: 2m 48s\n",
            "518:\tlearn: 0.0694827\ttotal: 3m 1s\tremaining: 2m 47s\n",
            "519:\tlearn: 0.0694447\ttotal: 3m 1s\tremaining: 2m 47s\n",
            "520:\tlearn: 0.0694073\ttotal: 3m 1s\tremaining: 2m 47s\n",
            "521:\tlearn: 0.0693835\ttotal: 3m 2s\tremaining: 2m 46s\n",
            "522:\tlearn: 0.0693659\ttotal: 3m 2s\tremaining: 2m 46s\n",
            "523:\tlearn: 0.0693325\ttotal: 3m 2s\tremaining: 2m 46s\n",
            "524:\tlearn: 0.0692913\ttotal: 3m 3s\tremaining: 2m 45s\n",
            "525:\tlearn: 0.0692457\ttotal: 3m 3s\tremaining: 2m 45s\n",
            "526:\tlearn: 0.0691942\ttotal: 3m 3s\tremaining: 2m 45s\n",
            "527:\tlearn: 0.0691554\ttotal: 3m 4s\tremaining: 2m 44s\n",
            "528:\tlearn: 0.0691538\ttotal: 3m 4s\tremaining: 2m 44s\n",
            "529:\tlearn: 0.0691023\ttotal: 3m 4s\tremaining: 2m 44s\n",
            "530:\tlearn: 0.0690482\ttotal: 3m 5s\tremaining: 2m 43s\n",
            "531:\tlearn: 0.0690207\ttotal: 3m 5s\tremaining: 2m 43s\n",
            "532:\tlearn: 0.0689897\ttotal: 3m 6s\tremaining: 2m 43s\n",
            "533:\tlearn: 0.0689503\ttotal: 3m 6s\tremaining: 2m 42s\n",
            "534:\tlearn: 0.0689293\ttotal: 3m 6s\tremaining: 2m 42s\n",
            "535:\tlearn: 0.0689037\ttotal: 3m 7s\tremaining: 2m 42s\n",
            "536:\tlearn: 0.0688665\ttotal: 3m 7s\tremaining: 2m 41s\n",
            "537:\tlearn: 0.0688349\ttotal: 3m 8s\tremaining: 2m 41s\n",
            "538:\tlearn: 0.0687957\ttotal: 3m 8s\tremaining: 2m 41s\n",
            "539:\tlearn: 0.0687502\ttotal: 3m 8s\tremaining: 2m 40s\n",
            "540:\tlearn: 0.0687306\ttotal: 3m 9s\tremaining: 2m 40s\n",
            "541:\tlearn: 0.0687023\ttotal: 3m 9s\tremaining: 2m 40s\n",
            "542:\tlearn: 0.0686880\ttotal: 3m 9s\tremaining: 2m 39s\n",
            "543:\tlearn: 0.0686435\ttotal: 3m 10s\tremaining: 2m 39s\n",
            "544:\tlearn: 0.0686211\ttotal: 3m 10s\tremaining: 2m 39s\n",
            "545:\tlearn: 0.0685850\ttotal: 3m 10s\tremaining: 2m 38s\n",
            "546:\tlearn: 0.0685542\ttotal: 3m 11s\tremaining: 2m 38s\n",
            "547:\tlearn: 0.0685296\ttotal: 3m 11s\tremaining: 2m 38s\n",
            "548:\tlearn: 0.0685000\ttotal: 3m 11s\tremaining: 2m 37s\n",
            "549:\tlearn: 0.0684746\ttotal: 3m 12s\tremaining: 2m 37s\n",
            "550:\tlearn: 0.0684406\ttotal: 3m 12s\tremaining: 2m 37s\n",
            "551:\tlearn: 0.0684274\ttotal: 3m 13s\tremaining: 2m 36s\n",
            "552:\tlearn: 0.0683675\ttotal: 3m 13s\tremaining: 2m 36s\n",
            "553:\tlearn: 0.0683441\ttotal: 3m 13s\tremaining: 2m 36s\n",
            "554:\tlearn: 0.0683415\ttotal: 3m 14s\tremaining: 2m 35s\n",
            "555:\tlearn: 0.0683190\ttotal: 3m 14s\tremaining: 2m 35s\n",
            "556:\tlearn: 0.0683041\ttotal: 3m 14s\tremaining: 2m 34s\n",
            "557:\tlearn: 0.0682760\ttotal: 3m 15s\tremaining: 2m 34s\n",
            "558:\tlearn: 0.0682722\ttotal: 3m 15s\tremaining: 2m 34s\n",
            "559:\tlearn: 0.0682425\ttotal: 3m 15s\tremaining: 2m 33s\n",
            "560:\tlearn: 0.0682148\ttotal: 3m 15s\tremaining: 2m 33s\n",
            "561:\tlearn: 0.0681751\ttotal: 3m 16s\tremaining: 2m 33s\n",
            "562:\tlearn: 0.0681374\ttotal: 3m 16s\tremaining: 2m 32s\n",
            "563:\tlearn: 0.0681317\ttotal: 3m 16s\tremaining: 2m 32s\n",
            "564:\tlearn: 0.0681176\ttotal: 3m 17s\tremaining: 2m 31s\n",
            "565:\tlearn: 0.0681112\ttotal: 3m 17s\tremaining: 2m 31s\n",
            "566:\tlearn: 0.0680875\ttotal: 3m 17s\tremaining: 2m 31s\n",
            "567:\tlearn: 0.0680777\ttotal: 3m 18s\tremaining: 2m 30s\n",
            "568:\tlearn: 0.0680692\ttotal: 3m 18s\tremaining: 2m 30s\n",
            "569:\tlearn: 0.0680432\ttotal: 3m 18s\tremaining: 2m 30s\n",
            "570:\tlearn: 0.0680207\ttotal: 3m 19s\tremaining: 2m 29s\n",
            "571:\tlearn: 0.0679951\ttotal: 3m 19s\tremaining: 2m 29s\n",
            "572:\tlearn: 0.0679617\ttotal: 3m 19s\tremaining: 2m 28s\n",
            "573:\tlearn: 0.0679535\ttotal: 3m 20s\tremaining: 2m 28s\n",
            "574:\tlearn: 0.0679235\ttotal: 3m 20s\tremaining: 2m 28s\n",
            "575:\tlearn: 0.0678934\ttotal: 3m 20s\tremaining: 2m 27s\n",
            "576:\tlearn: 0.0678698\ttotal: 3m 21s\tremaining: 2m 27s\n",
            "577:\tlearn: 0.0678409\ttotal: 3m 21s\tremaining: 2m 27s\n",
            "578:\tlearn: 0.0677830\ttotal: 3m 22s\tremaining: 2m 26s\n",
            "579:\tlearn: 0.0677465\ttotal: 3m 22s\tremaining: 2m 26s\n",
            "580:\tlearn: 0.0677109\ttotal: 3m 22s\tremaining: 2m 26s\n",
            "581:\tlearn: 0.0676709\ttotal: 3m 23s\tremaining: 2m 25s\n",
            "582:\tlearn: 0.0676608\ttotal: 3m 23s\tremaining: 2m 25s\n",
            "583:\tlearn: 0.0676215\ttotal: 3m 23s\tremaining: 2m 25s\n",
            "584:\tlearn: 0.0675756\ttotal: 3m 24s\tremaining: 2m 24s\n",
            "585:\tlearn: 0.0675497\ttotal: 3m 24s\tremaining: 2m 24s\n",
            "586:\tlearn: 0.0674986\ttotal: 3m 24s\tremaining: 2m 24s\n",
            "587:\tlearn: 0.0674776\ttotal: 3m 25s\tremaining: 2m 23s\n",
            "588:\tlearn: 0.0674592\ttotal: 3m 25s\tremaining: 2m 23s\n",
            "589:\tlearn: 0.0674353\ttotal: 3m 25s\tremaining: 2m 23s\n",
            "590:\tlearn: 0.0674175\ttotal: 3m 26s\tremaining: 2m 22s\n",
            "591:\tlearn: 0.0673941\ttotal: 3m 26s\tremaining: 2m 22s\n",
            "592:\tlearn: 0.0673900\ttotal: 3m 26s\tremaining: 2m 21s\n",
            "593:\tlearn: 0.0673704\ttotal: 3m 27s\tremaining: 2m 21s\n",
            "594:\tlearn: 0.0673487\ttotal: 3m 27s\tremaining: 2m 21s\n",
            "595:\tlearn: 0.0673200\ttotal: 3m 27s\tremaining: 2m 20s\n",
            "596:\tlearn: 0.0672911\ttotal: 3m 28s\tremaining: 2m 20s\n",
            "597:\tlearn: 0.0672781\ttotal: 3m 28s\tremaining: 2m 20s\n",
            "598:\tlearn: 0.0672369\ttotal: 3m 28s\tremaining: 2m 19s\n",
            "599:\tlearn: 0.0672345\ttotal: 3m 29s\tremaining: 2m 19s\n",
            "600:\tlearn: 0.0672065\ttotal: 3m 29s\tremaining: 2m 19s\n",
            "601:\tlearn: 0.0671919\ttotal: 3m 29s\tremaining: 2m 18s\n",
            "602:\tlearn: 0.0671807\ttotal: 3m 30s\tremaining: 2m 18s\n",
            "603:\tlearn: 0.0671599\ttotal: 3m 30s\tremaining: 2m 17s\n",
            "604:\tlearn: 0.0671310\ttotal: 3m 30s\tremaining: 2m 17s\n",
            "605:\tlearn: 0.0671103\ttotal: 3m 31s\tremaining: 2m 17s\n",
            "606:\tlearn: 0.0670968\ttotal: 3m 31s\tremaining: 2m 16s\n",
            "607:\tlearn: 0.0670828\ttotal: 3m 31s\tremaining: 2m 16s\n",
            "608:\tlearn: 0.0670429\ttotal: 3m 32s\tremaining: 2m 16s\n",
            "609:\tlearn: 0.0670269\ttotal: 3m 32s\tremaining: 2m 15s\n",
            "610:\tlearn: 0.0669765\ttotal: 3m 32s\tremaining: 2m 15s\n",
            "611:\tlearn: 0.0669577\ttotal: 3m 33s\tremaining: 2m 15s\n",
            "612:\tlearn: 0.0669393\ttotal: 3m 33s\tremaining: 2m 14s\n",
            "613:\tlearn: 0.0669124\ttotal: 3m 33s\tremaining: 2m 14s\n",
            "614:\tlearn: 0.0668918\ttotal: 3m 34s\tremaining: 2m 14s\n",
            "615:\tlearn: 0.0668695\ttotal: 3m 34s\tremaining: 2m 13s\n",
            "616:\tlearn: 0.0668545\ttotal: 3m 34s\tremaining: 2m 13s\n",
            "617:\tlearn: 0.0668351\ttotal: 3m 35s\tremaining: 2m 13s\n",
            "618:\tlearn: 0.0668025\ttotal: 3m 35s\tremaining: 2m 12s\n",
            "619:\tlearn: 0.0667590\ttotal: 3m 35s\tremaining: 2m 12s\n",
            "620:\tlearn: 0.0667223\ttotal: 3m 36s\tremaining: 2m 12s\n",
            "621:\tlearn: 0.0667061\ttotal: 3m 36s\tremaining: 2m 11s\n",
            "622:\tlearn: 0.0666651\ttotal: 3m 37s\tremaining: 2m 11s\n",
            "623:\tlearn: 0.0666592\ttotal: 3m 37s\tremaining: 2m 10s\n",
            "624:\tlearn: 0.0666406\ttotal: 3m 37s\tremaining: 2m 10s\n",
            "625:\tlearn: 0.0666193\ttotal: 3m 38s\tremaining: 2m 10s\n",
            "626:\tlearn: 0.0665893\ttotal: 3m 38s\tremaining: 2m 9s\n",
            "627:\tlearn: 0.0665692\ttotal: 3m 38s\tremaining: 2m 9s\n",
            "628:\tlearn: 0.0665258\ttotal: 3m 39s\tremaining: 2m 9s\n",
            "629:\tlearn: 0.0665201\ttotal: 3m 39s\tremaining: 2m 8s\n",
            "630:\tlearn: 0.0664946\ttotal: 3m 39s\tremaining: 2m 8s\n",
            "631:\tlearn: 0.0664443\ttotal: 3m 40s\tremaining: 2m 8s\n",
            "632:\tlearn: 0.0664213\ttotal: 3m 40s\tremaining: 2m 7s\n",
            "633:\tlearn: 0.0663800\ttotal: 3m 40s\tremaining: 2m 7s\n",
            "634:\tlearn: 0.0663720\ttotal: 3m 41s\tremaining: 2m 7s\n",
            "635:\tlearn: 0.0663687\ttotal: 3m 41s\tremaining: 2m 6s\n",
            "636:\tlearn: 0.0663487\ttotal: 3m 41s\tremaining: 2m 6s\n",
            "637:\tlearn: 0.0663186\ttotal: 3m 42s\tremaining: 2m 6s\n",
            "638:\tlearn: 0.0662816\ttotal: 3m 42s\tremaining: 2m 5s\n",
            "639:\tlearn: 0.0662608\ttotal: 3m 42s\tremaining: 2m 5s\n",
            "640:\tlearn: 0.0662349\ttotal: 3m 43s\tremaining: 2m 5s\n",
            "641:\tlearn: 0.0662150\ttotal: 3m 43s\tremaining: 2m 4s\n",
            "642:\tlearn: 0.0661892\ttotal: 3m 43s\tremaining: 2m 4s\n",
            "643:\tlearn: 0.0661739\ttotal: 3m 44s\tremaining: 2m 4s\n",
            "644:\tlearn: 0.0661725\ttotal: 3m 44s\tremaining: 2m 3s\n",
            "645:\tlearn: 0.0661611\ttotal: 3m 44s\tremaining: 2m 3s\n",
            "646:\tlearn: 0.0661506\ttotal: 3m 45s\tremaining: 2m 2s\n",
            "647:\tlearn: 0.0661257\ttotal: 3m 45s\tremaining: 2m 2s\n",
            "648:\tlearn: 0.0661053\ttotal: 3m 45s\tremaining: 2m 2s\n",
            "649:\tlearn: 0.0660661\ttotal: 3m 46s\tremaining: 2m 1s\n",
            "650:\tlearn: 0.0660548\ttotal: 3m 46s\tremaining: 2m 1s\n",
            "651:\tlearn: 0.0660058\ttotal: 3m 46s\tremaining: 2m 1s\n",
            "652:\tlearn: 0.0659878\ttotal: 3m 47s\tremaining: 2m\n",
            "653:\tlearn: 0.0659600\ttotal: 3m 47s\tremaining: 2m\n",
            "654:\tlearn: 0.0659366\ttotal: 3m 47s\tremaining: 2m\n",
            "655:\tlearn: 0.0658822\ttotal: 3m 48s\tremaining: 1m 59s\n",
            "656:\tlearn: 0.0658599\ttotal: 3m 48s\tremaining: 1m 59s\n",
            "657:\tlearn: 0.0658425\ttotal: 3m 49s\tremaining: 1m 59s\n",
            "658:\tlearn: 0.0658088\ttotal: 3m 49s\tremaining: 1m 58s\n",
            "659:\tlearn: 0.0657788\ttotal: 3m 49s\tremaining: 1m 58s\n",
            "660:\tlearn: 0.0657449\ttotal: 3m 50s\tremaining: 1m 58s\n",
            "661:\tlearn: 0.0657417\ttotal: 3m 50s\tremaining: 1m 57s\n",
            "662:\tlearn: 0.0657268\ttotal: 3m 50s\tremaining: 1m 57s\n",
            "663:\tlearn: 0.0657062\ttotal: 3m 51s\tremaining: 1m 56s\n",
            "664:\tlearn: 0.0656927\ttotal: 3m 51s\tremaining: 1m 56s\n",
            "665:\tlearn: 0.0656844\ttotal: 3m 51s\tremaining: 1m 56s\n",
            "666:\tlearn: 0.0656498\ttotal: 3m 52s\tremaining: 1m 55s\n",
            "667:\tlearn: 0.0656449\ttotal: 3m 52s\tremaining: 1m 55s\n",
            "668:\tlearn: 0.0656106\ttotal: 3m 52s\tremaining: 1m 55s\n",
            "669:\tlearn: 0.0655912\ttotal: 3m 53s\tremaining: 1m 54s\n",
            "670:\tlearn: 0.0655788\ttotal: 3m 53s\tremaining: 1m 54s\n",
            "671:\tlearn: 0.0655345\ttotal: 3m 53s\tremaining: 1m 54s\n",
            "672:\tlearn: 0.0655011\ttotal: 3m 54s\tremaining: 1m 53s\n",
            "673:\tlearn: 0.0654937\ttotal: 3m 54s\tremaining: 1m 53s\n",
            "674:\tlearn: 0.0654627\ttotal: 3m 54s\tremaining: 1m 53s\n",
            "675:\tlearn: 0.0654332\ttotal: 3m 55s\tremaining: 1m 52s\n",
            "676:\tlearn: 0.0653943\ttotal: 3m 55s\tremaining: 1m 52s\n",
            "677:\tlearn: 0.0653716\ttotal: 3m 56s\tremaining: 1m 52s\n",
            "678:\tlearn: 0.0653392\ttotal: 3m 56s\tremaining: 1m 51s\n",
            "679:\tlearn: 0.0652753\ttotal: 3m 56s\tremaining: 1m 51s\n",
            "680:\tlearn: 0.0652401\ttotal: 3m 57s\tremaining: 1m 51s\n",
            "681:\tlearn: 0.0652188\ttotal: 3m 57s\tremaining: 1m 50s\n",
            "682:\tlearn: 0.0651958\ttotal: 3m 57s\tremaining: 1m 50s\n",
            "683:\tlearn: 0.0651659\ttotal: 3m 58s\tremaining: 1m 50s\n",
            "684:\tlearn: 0.0651094\ttotal: 3m 58s\tremaining: 1m 49s\n",
            "685:\tlearn: 0.0650717\ttotal: 3m 59s\tremaining: 1m 49s\n",
            "686:\tlearn: 0.0650385\ttotal: 3m 59s\tremaining: 1m 49s\n",
            "687:\tlearn: 0.0650226\ttotal: 3m 59s\tremaining: 1m 48s\n",
            "688:\tlearn: 0.0650071\ttotal: 4m\tremaining: 1m 48s\n",
            "689:\tlearn: 0.0649933\ttotal: 4m\tremaining: 1m 48s\n",
            "690:\tlearn: 0.0649690\ttotal: 4m\tremaining: 1m 47s\n",
            "691:\tlearn: 0.0649403\ttotal: 4m 1s\tremaining: 1m 47s\n",
            "692:\tlearn: 0.0649177\ttotal: 4m 1s\tremaining: 1m 47s\n",
            "693:\tlearn: 0.0648818\ttotal: 4m 2s\tremaining: 1m 46s\n",
            "694:\tlearn: 0.0648654\ttotal: 4m 2s\tremaining: 1m 46s\n",
            "695:\tlearn: 0.0648598\ttotal: 4m 2s\tremaining: 1m 46s\n",
            "696:\tlearn: 0.0648180\ttotal: 4m 3s\tremaining: 1m 45s\n",
            "697:\tlearn: 0.0648075\ttotal: 4m 3s\tremaining: 1m 45s\n",
            "698:\tlearn: 0.0647821\ttotal: 4m 3s\tremaining: 1m 44s\n",
            "699:\tlearn: 0.0647725\ttotal: 4m 4s\tremaining: 1m 44s\n",
            "700:\tlearn: 0.0647509\ttotal: 4m 4s\tremaining: 1m 44s\n",
            "701:\tlearn: 0.0647165\ttotal: 4m 4s\tremaining: 1m 43s\n",
            "702:\tlearn: 0.0646957\ttotal: 4m 5s\tremaining: 1m 43s\n",
            "703:\tlearn: 0.0646891\ttotal: 4m 5s\tremaining: 1m 43s\n",
            "704:\tlearn: 0.0646751\ttotal: 4m 6s\tremaining: 1m 42s\n",
            "705:\tlearn: 0.0646500\ttotal: 4m 6s\tremaining: 1m 42s\n",
            "706:\tlearn: 0.0646368\ttotal: 4m 6s\tremaining: 1m 42s\n",
            "707:\tlearn: 0.0646163\ttotal: 4m 7s\tremaining: 1m 41s\n",
            "708:\tlearn: 0.0645567\ttotal: 4m 7s\tremaining: 1m 41s\n",
            "709:\tlearn: 0.0645554\ttotal: 4m 7s\tremaining: 1m 41s\n",
            "710:\tlearn: 0.0645257\ttotal: 4m 8s\tremaining: 1m 40s\n",
            "711:\tlearn: 0.0644906\ttotal: 4m 8s\tremaining: 1m 40s\n",
            "712:\tlearn: 0.0644791\ttotal: 4m 8s\tremaining: 1m 40s\n",
            "713:\tlearn: 0.0644675\ttotal: 4m 9s\tremaining: 1m 39s\n",
            "714:\tlearn: 0.0644575\ttotal: 4m 9s\tremaining: 1m 39s\n",
            "715:\tlearn: 0.0644227\ttotal: 4m 9s\tremaining: 1m 39s\n",
            "716:\tlearn: 0.0643910\ttotal: 4m 10s\tremaining: 1m 38s\n",
            "717:\tlearn: 0.0643715\ttotal: 4m 10s\tremaining: 1m 38s\n",
            "718:\tlearn: 0.0643270\ttotal: 4m 10s\tremaining: 1m 38s\n",
            "719:\tlearn: 0.0643068\ttotal: 4m 11s\tremaining: 1m 37s\n",
            "720:\tlearn: 0.0642622\ttotal: 4m 11s\tremaining: 1m 37s\n",
            "721:\tlearn: 0.0642561\ttotal: 4m 11s\tremaining: 1m 36s\n",
            "722:\tlearn: 0.0642227\ttotal: 4m 12s\tremaining: 1m 36s\n",
            "723:\tlearn: 0.0641769\ttotal: 4m 12s\tremaining: 1m 36s\n",
            "724:\tlearn: 0.0641480\ttotal: 4m 12s\tremaining: 1m 35s\n",
            "725:\tlearn: 0.0641182\ttotal: 4m 13s\tremaining: 1m 35s\n",
            "726:\tlearn: 0.0640832\ttotal: 4m 13s\tremaining: 1m 35s\n",
            "727:\tlearn: 0.0640603\ttotal: 4m 14s\tremaining: 1m 34s\n",
            "728:\tlearn: 0.0640492\ttotal: 4m 14s\tremaining: 1m 34s\n",
            "729:\tlearn: 0.0640373\ttotal: 4m 14s\tremaining: 1m 34s\n",
            "730:\tlearn: 0.0640109\ttotal: 4m 15s\tremaining: 1m 33s\n",
            "731:\tlearn: 0.0640029\ttotal: 4m 15s\tremaining: 1m 33s\n",
            "732:\tlearn: 0.0639729\ttotal: 4m 15s\tremaining: 1m 33s\n",
            "733:\tlearn: 0.0639564\ttotal: 4m 16s\tremaining: 1m 32s\n",
            "734:\tlearn: 0.0639530\ttotal: 4m 16s\tremaining: 1m 32s\n",
            "735:\tlearn: 0.0639176\ttotal: 4m 16s\tremaining: 1m 32s\n",
            "736:\tlearn: 0.0638888\ttotal: 4m 17s\tremaining: 1m 31s\n",
            "737:\tlearn: 0.0638753\ttotal: 4m 17s\tremaining: 1m 31s\n",
            "738:\tlearn: 0.0638582\ttotal: 4m 17s\tremaining: 1m 31s\n",
            "739:\tlearn: 0.0638530\ttotal: 4m 18s\tremaining: 1m 30s\n",
            "740:\tlearn: 0.0638488\ttotal: 4m 18s\tremaining: 1m 30s\n",
            "741:\tlearn: 0.0638170\ttotal: 4m 18s\tremaining: 1m 29s\n",
            "742:\tlearn: 0.0638002\ttotal: 4m 19s\tremaining: 1m 29s\n",
            "743:\tlearn: 0.0637828\ttotal: 4m 19s\tremaining: 1m 29s\n",
            "744:\tlearn: 0.0637507\ttotal: 4m 19s\tremaining: 1m 28s\n",
            "745:\tlearn: 0.0637349\ttotal: 4m 20s\tremaining: 1m 28s\n",
            "746:\tlearn: 0.0637317\ttotal: 4m 20s\tremaining: 1m 28s\n",
            "747:\tlearn: 0.0637105\ttotal: 4m 20s\tremaining: 1m 27s\n",
            "748:\tlearn: 0.0636843\ttotal: 4m 21s\tremaining: 1m 27s\n",
            "749:\tlearn: 0.0636550\ttotal: 4m 21s\tremaining: 1m 27s\n",
            "750:\tlearn: 0.0636124\ttotal: 4m 21s\tremaining: 1m 26s\n",
            "751:\tlearn: 0.0635993\ttotal: 4m 22s\tremaining: 1m 26s\n",
            "752:\tlearn: 0.0635707\ttotal: 4m 22s\tremaining: 1m 26s\n",
            "753:\tlearn: 0.0635654\ttotal: 4m 22s\tremaining: 1m 25s\n",
            "754:\tlearn: 0.0635615\ttotal: 4m 23s\tremaining: 1m 25s\n",
            "755:\tlearn: 0.0635449\ttotal: 4m 23s\tremaining: 1m 25s\n",
            "756:\tlearn: 0.0635353\ttotal: 4m 23s\tremaining: 1m 24s\n",
            "757:\tlearn: 0.0635197\ttotal: 4m 24s\tremaining: 1m 24s\n",
            "758:\tlearn: 0.0635084\ttotal: 4m 24s\tremaining: 1m 24s\n",
            "759:\tlearn: 0.0634919\ttotal: 4m 24s\tremaining: 1m 23s\n",
            "760:\tlearn: 0.0634743\ttotal: 4m 25s\tremaining: 1m 23s\n",
            "761:\tlearn: 0.0634728\ttotal: 4m 25s\tremaining: 1m 22s\n",
            "762:\tlearn: 0.0634618\ttotal: 4m 25s\tremaining: 1m 22s\n",
            "763:\tlearn: 0.0634513\ttotal: 4m 26s\tremaining: 1m 22s\n",
            "764:\tlearn: 0.0634311\ttotal: 4m 26s\tremaining: 1m 21s\n",
            "765:\tlearn: 0.0634045\ttotal: 4m 27s\tremaining: 1m 21s\n",
            "766:\tlearn: 0.0633792\ttotal: 4m 27s\tremaining: 1m 21s\n",
            "767:\tlearn: 0.0633585\ttotal: 4m 27s\tremaining: 1m 20s\n",
            "768:\tlearn: 0.0633331\ttotal: 4m 28s\tremaining: 1m 20s\n",
            "769:\tlearn: 0.0633283\ttotal: 4m 28s\tremaining: 1m 20s\n",
            "770:\tlearn: 0.0633209\ttotal: 4m 28s\tremaining: 1m 19s\n",
            "771:\tlearn: 0.0633126\ttotal: 4m 29s\tremaining: 1m 19s\n",
            "772:\tlearn: 0.0632916\ttotal: 4m 29s\tremaining: 1m 19s\n",
            "773:\tlearn: 0.0632739\ttotal: 4m 29s\tremaining: 1m 18s\n",
            "774:\tlearn: 0.0632685\ttotal: 4m 30s\tremaining: 1m 18s\n",
            "775:\tlearn: 0.0632634\ttotal: 4m 30s\tremaining: 1m 18s\n",
            "776:\tlearn: 0.0632379\ttotal: 4m 30s\tremaining: 1m 17s\n",
            "777:\tlearn: 0.0632346\ttotal: 4m 30s\tremaining: 1m 17s\n",
            "778:\tlearn: 0.0632119\ttotal: 4m 31s\tremaining: 1m 16s\n",
            "779:\tlearn: 0.0631924\ttotal: 4m 31s\tremaining: 1m 16s\n",
            "780:\tlearn: 0.0631740\ttotal: 4m 32s\tremaining: 1m 16s\n",
            "781:\tlearn: 0.0631649\ttotal: 4m 32s\tremaining: 1m 15s\n",
            "782:\tlearn: 0.0631473\ttotal: 4m 32s\tremaining: 1m 15s\n",
            "783:\tlearn: 0.0631416\ttotal: 4m 33s\tremaining: 1m 15s\n",
            "784:\tlearn: 0.0631373\ttotal: 4m 33s\tremaining: 1m 14s\n",
            "785:\tlearn: 0.0631223\ttotal: 4m 33s\tremaining: 1m 14s\n",
            "786:\tlearn: 0.0630854\ttotal: 4m 34s\tremaining: 1m 14s\n",
            "787:\tlearn: 0.0630245\ttotal: 4m 34s\tremaining: 1m 13s\n",
            "788:\tlearn: 0.0629973\ttotal: 4m 34s\tremaining: 1m 13s\n",
            "789:\tlearn: 0.0629884\ttotal: 4m 35s\tremaining: 1m 13s\n",
            "790:\tlearn: 0.0629635\ttotal: 4m 35s\tremaining: 1m 12s\n",
            "791:\tlearn: 0.0629599\ttotal: 4m 35s\tremaining: 1m 12s\n",
            "792:\tlearn: 0.0629369\ttotal: 4m 36s\tremaining: 1m 12s\n",
            "793:\tlearn: 0.0629188\ttotal: 4m 36s\tremaining: 1m 11s\n",
            "794:\tlearn: 0.0628975\ttotal: 4m 36s\tremaining: 1m 11s\n",
            "795:\tlearn: 0.0628939\ttotal: 4m 37s\tremaining: 1m 11s\n",
            "796:\tlearn: 0.0628913\ttotal: 4m 37s\tremaining: 1m 10s\n",
            "797:\tlearn: 0.0628845\ttotal: 4m 37s\tremaining: 1m 10s\n",
            "798:\tlearn: 0.0628696\ttotal: 4m 38s\tremaining: 1m 9s\n",
            "799:\tlearn: 0.0628454\ttotal: 4m 38s\tremaining: 1m 9s\n",
            "800:\tlearn: 0.0628199\ttotal: 4m 38s\tremaining: 1m 9s\n",
            "801:\tlearn: 0.0627965\ttotal: 4m 39s\tremaining: 1m 8s\n",
            "802:\tlearn: 0.0627947\ttotal: 4m 39s\tremaining: 1m 8s\n",
            "803:\tlearn: 0.0627811\ttotal: 4m 39s\tremaining: 1m 8s\n",
            "804:\tlearn: 0.0627586\ttotal: 4m 39s\tremaining: 1m 7s\n",
            "805:\tlearn: 0.0627466\ttotal: 4m 40s\tremaining: 1m 7s\n",
            "806:\tlearn: 0.0626977\ttotal: 4m 40s\tremaining: 1m 7s\n",
            "807:\tlearn: 0.0626936\ttotal: 4m 40s\tremaining: 1m 6s\n",
            "808:\tlearn: 0.0626722\ttotal: 4m 41s\tremaining: 1m 6s\n",
            "809:\tlearn: 0.0626407\ttotal: 4m 41s\tremaining: 1m 6s\n",
            "810:\tlearn: 0.0626390\ttotal: 4m 41s\tremaining: 1m 5s\n",
            "811:\tlearn: 0.0626025\ttotal: 4m 42s\tremaining: 1m 5s\n",
            "812:\tlearn: 0.0626008\ttotal: 4m 42s\tremaining: 1m 5s\n",
            "813:\tlearn: 0.0625688\ttotal: 4m 43s\tremaining: 1m 4s\n",
            "814:\tlearn: 0.0625564\ttotal: 4m 43s\tremaining: 1m 4s\n",
            "815:\tlearn: 0.0625295\ttotal: 4m 43s\tremaining: 1m 4s\n",
            "816:\tlearn: 0.0624985\ttotal: 4m 44s\tremaining: 1m 3s\n",
            "817:\tlearn: 0.0624941\ttotal: 4m 44s\tremaining: 1m 3s\n",
            "818:\tlearn: 0.0624890\ttotal: 4m 45s\tremaining: 1m 2s\n",
            "819:\tlearn: 0.0624384\ttotal: 4m 45s\tremaining: 1m 2s\n",
            "820:\tlearn: 0.0624188\ttotal: 4m 45s\tremaining: 1m 2s\n",
            "821:\tlearn: 0.0624130\ttotal: 4m 46s\tremaining: 1m 1s\n",
            "822:\tlearn: 0.0623853\ttotal: 4m 46s\tremaining: 1m 1s\n",
            "823:\tlearn: 0.0623611\ttotal: 4m 46s\tremaining: 1m 1s\n",
            "824:\tlearn: 0.0623393\ttotal: 4m 47s\tremaining: 1m\n",
            "825:\tlearn: 0.0623170\ttotal: 4m 47s\tremaining: 1m\n",
            "826:\tlearn: 0.0623041\ttotal: 4m 47s\tremaining: 1m\n",
            "827:\tlearn: 0.0622903\ttotal: 4m 48s\tremaining: 59.9s\n",
            "828:\tlearn: 0.0622832\ttotal: 4m 48s\tremaining: 59.5s\n",
            "829:\tlearn: 0.0622605\ttotal: 4m 48s\tremaining: 59.2s\n",
            "830:\tlearn: 0.0622515\ttotal: 4m 49s\tremaining: 58.8s\n",
            "831:\tlearn: 0.0622243\ttotal: 4m 49s\tremaining: 58.5s\n",
            "832:\tlearn: 0.0622204\ttotal: 4m 50s\tremaining: 58.1s\n",
            "833:\tlearn: 0.0622096\ttotal: 4m 50s\tremaining: 57.8s\n",
            "834:\tlearn: 0.0621794\ttotal: 4m 50s\tremaining: 57.5s\n",
            "835:\tlearn: 0.0621595\ttotal: 4m 51s\tremaining: 57.2s\n",
            "836:\tlearn: 0.0621356\ttotal: 4m 51s\tremaining: 56.8s\n",
            "837:\tlearn: 0.0620940\ttotal: 4m 52s\tremaining: 56.5s\n",
            "838:\tlearn: 0.0620735\ttotal: 4m 52s\tremaining: 56.1s\n",
            "839:\tlearn: 0.0620641\ttotal: 4m 52s\tremaining: 55.8s\n",
            "840:\tlearn: 0.0620548\ttotal: 4m 53s\tremaining: 55.4s\n",
            "841:\tlearn: 0.0620165\ttotal: 4m 53s\tremaining: 55.1s\n",
            "842:\tlearn: 0.0620062\ttotal: 4m 53s\tremaining: 54.7s\n",
            "843:\tlearn: 0.0620005\ttotal: 4m 54s\tremaining: 54.4s\n",
            "844:\tlearn: 0.0619739\ttotal: 4m 54s\tremaining: 54s\n",
            "845:\tlearn: 0.0619549\ttotal: 4m 54s\tremaining: 53.7s\n",
            "846:\tlearn: 0.0619367\ttotal: 4m 55s\tremaining: 53.3s\n",
            "847:\tlearn: 0.0619233\ttotal: 4m 55s\tremaining: 53s\n",
            "848:\tlearn: 0.0619201\ttotal: 4m 55s\tremaining: 52.6s\n",
            "849:\tlearn: 0.0619014\ttotal: 4m 56s\tremaining: 52.3s\n",
            "850:\tlearn: 0.0618783\ttotal: 4m 56s\tremaining: 51.9s\n",
            "851:\tlearn: 0.0618751\ttotal: 4m 56s\tremaining: 51.6s\n",
            "852:\tlearn: 0.0618531\ttotal: 4m 57s\tremaining: 51.2s\n",
            "853:\tlearn: 0.0618498\ttotal: 4m 57s\tremaining: 50.9s\n",
            "854:\tlearn: 0.0618366\ttotal: 4m 57s\tremaining: 50.5s\n",
            "855:\tlearn: 0.0618066\ttotal: 4m 58s\tremaining: 50.2s\n",
            "856:\tlearn: 0.0617992\ttotal: 4m 58s\tremaining: 49.8s\n",
            "857:\tlearn: 0.0617748\ttotal: 4m 58s\tremaining: 49.5s\n",
            "858:\tlearn: 0.0617347\ttotal: 4m 59s\tremaining: 49.1s\n",
            "859:\tlearn: 0.0617284\ttotal: 4m 59s\tremaining: 48.8s\n",
            "860:\tlearn: 0.0617229\ttotal: 5m\tremaining: 48.4s\n",
            "861:\tlearn: 0.0616895\ttotal: 5m\tremaining: 48.1s\n",
            "862:\tlearn: 0.0616863\ttotal: 5m\tremaining: 47.8s\n",
            "863:\tlearn: 0.0616794\ttotal: 5m 1s\tremaining: 47.4s\n",
            "864:\tlearn: 0.0616443\ttotal: 5m 1s\tremaining: 47.1s\n",
            "865:\tlearn: 0.0616269\ttotal: 5m 1s\tremaining: 46.7s\n",
            "866:\tlearn: 0.0616210\ttotal: 5m 2s\tremaining: 46.3s\n",
            "867:\tlearn: 0.0616098\ttotal: 5m 2s\tremaining: 46s\n",
            "868:\tlearn: 0.0615950\ttotal: 5m 2s\tremaining: 45.6s\n",
            "869:\tlearn: 0.0615825\ttotal: 5m 3s\tremaining: 45.3s\n",
            "870:\tlearn: 0.0615639\ttotal: 5m 3s\tremaining: 44.9s\n",
            "871:\tlearn: 0.0615399\ttotal: 5m 3s\tremaining: 44.6s\n",
            "872:\tlearn: 0.0615115\ttotal: 5m 4s\tremaining: 44.2s\n",
            "873:\tlearn: 0.0614989\ttotal: 5m 4s\tremaining: 43.9s\n",
            "874:\tlearn: 0.0614950\ttotal: 5m 4s\tremaining: 43.5s\n",
            "875:\tlearn: 0.0614602\ttotal: 5m 5s\tremaining: 43.2s\n",
            "876:\tlearn: 0.0614453\ttotal: 5m 5s\tremaining: 42.9s\n",
            "877:\tlearn: 0.0614234\ttotal: 5m 6s\tremaining: 42.5s\n",
            "878:\tlearn: 0.0614215\ttotal: 5m 6s\tremaining: 42.2s\n",
            "879:\tlearn: 0.0614098\ttotal: 5m 6s\tremaining: 41.8s\n",
            "880:\tlearn: 0.0613999\ttotal: 5m 6s\tremaining: 41.5s\n",
            "881:\tlearn: 0.0613745\ttotal: 5m 7s\tremaining: 41.1s\n",
            "882:\tlearn: 0.0613488\ttotal: 5m 7s\tremaining: 40.8s\n",
            "883:\tlearn: 0.0613308\ttotal: 5m 7s\tremaining: 40.4s\n",
            "884:\tlearn: 0.0613208\ttotal: 5m 8s\tremaining: 40.1s\n",
            "885:\tlearn: 0.0612949\ttotal: 5m 8s\tremaining: 39.7s\n",
            "886:\tlearn: 0.0612727\ttotal: 5m 8s\tremaining: 39.4s\n",
            "887:\tlearn: 0.0612654\ttotal: 5m 9s\tremaining: 39s\n",
            "888:\tlearn: 0.0612439\ttotal: 5m 9s\tremaining: 38.7s\n",
            "889:\tlearn: 0.0612136\ttotal: 5m 10s\tremaining: 38.3s\n",
            "890:\tlearn: 0.0611925\ttotal: 5m 10s\tremaining: 38s\n",
            "891:\tlearn: 0.0611734\ttotal: 5m 10s\tremaining: 37.6s\n",
            "892:\tlearn: 0.0611585\ttotal: 5m 11s\tremaining: 37.3s\n",
            "893:\tlearn: 0.0611502\ttotal: 5m 11s\tremaining: 36.9s\n",
            "894:\tlearn: 0.0611321\ttotal: 5m 11s\tremaining: 36.6s\n",
            "895:\tlearn: 0.0611227\ttotal: 5m 12s\tremaining: 36.2s\n",
            "896:\tlearn: 0.0611138\ttotal: 5m 12s\tremaining: 35.9s\n",
            "897:\tlearn: 0.0610824\ttotal: 5m 12s\tremaining: 35.5s\n",
            "898:\tlearn: 0.0610535\ttotal: 5m 13s\tremaining: 35.2s\n",
            "899:\tlearn: 0.0610358\ttotal: 5m 13s\tremaining: 34.8s\n",
            "900:\tlearn: 0.0610294\ttotal: 5m 13s\tremaining: 34.5s\n",
            "901:\tlearn: 0.0610273\ttotal: 5m 14s\tremaining: 34.1s\n",
            "902:\tlearn: 0.0610107\ttotal: 5m 14s\tremaining: 33.8s\n",
            "903:\tlearn: 0.0609933\ttotal: 5m 14s\tremaining: 33.4s\n",
            "904:\tlearn: 0.0609881\ttotal: 5m 15s\tremaining: 33.1s\n",
            "905:\tlearn: 0.0609832\ttotal: 5m 15s\tremaining: 32.7s\n",
            "906:\tlearn: 0.0609707\ttotal: 5m 15s\tremaining: 32.4s\n",
            "907:\tlearn: 0.0609464\ttotal: 5m 16s\tremaining: 32s\n",
            "908:\tlearn: 0.0609432\ttotal: 5m 16s\tremaining: 31.7s\n",
            "909:\tlearn: 0.0609143\ttotal: 5m 16s\tremaining: 31.3s\n",
            "910:\tlearn: 0.0609068\ttotal: 5m 17s\tremaining: 31s\n",
            "911:\tlearn: 0.0608885\ttotal: 5m 17s\tremaining: 30.6s\n",
            "912:\tlearn: 0.0608722\ttotal: 5m 17s\tremaining: 30.3s\n",
            "913:\tlearn: 0.0608576\ttotal: 5m 18s\tremaining: 29.9s\n",
            "914:\tlearn: 0.0608330\ttotal: 5m 18s\tremaining: 29.6s\n",
            "915:\tlearn: 0.0608264\ttotal: 5m 18s\tremaining: 29.2s\n",
            "916:\tlearn: 0.0608031\ttotal: 5m 19s\tremaining: 28.9s\n",
            "917:\tlearn: 0.0607878\ttotal: 5m 19s\tremaining: 28.6s\n",
            "918:\tlearn: 0.0607834\ttotal: 5m 19s\tremaining: 28.2s\n",
            "919:\tlearn: 0.0607764\ttotal: 5m 20s\tremaining: 27.9s\n",
            "920:\tlearn: 0.0607505\ttotal: 5m 20s\tremaining: 27.5s\n",
            "921:\tlearn: 0.0607243\ttotal: 5m 21s\tremaining: 27.2s\n",
            "922:\tlearn: 0.0607166\ttotal: 5m 22s\tremaining: 26.9s\n",
            "923:\tlearn: 0.0606841\ttotal: 5m 22s\tremaining: 26.5s\n",
            "924:\tlearn: 0.0606773\ttotal: 5m 22s\tremaining: 26.2s\n",
            "925:\tlearn: 0.0606713\ttotal: 5m 23s\tremaining: 25.8s\n",
            "926:\tlearn: 0.0606624\ttotal: 5m 23s\tremaining: 25.5s\n",
            "927:\tlearn: 0.0606565\ttotal: 5m 23s\tremaining: 25.1s\n",
            "928:\tlearn: 0.0606320\ttotal: 5m 24s\tremaining: 24.8s\n",
            "929:\tlearn: 0.0606304\ttotal: 5m 24s\tremaining: 24.4s\n",
            "930:\tlearn: 0.0606273\ttotal: 5m 24s\tremaining: 24.1s\n",
            "931:\tlearn: 0.0606028\ttotal: 5m 25s\tremaining: 23.7s\n",
            "932:\tlearn: 0.0605685\ttotal: 5m 25s\tremaining: 23.4s\n",
            "933:\tlearn: 0.0605576\ttotal: 5m 25s\tremaining: 23s\n",
            "934:\tlearn: 0.0605339\ttotal: 5m 26s\tremaining: 22.7s\n",
            "935:\tlearn: 0.0605136\ttotal: 5m 26s\tremaining: 22.3s\n",
            "936:\tlearn: 0.0604855\ttotal: 5m 27s\tremaining: 22s\n",
            "937:\tlearn: 0.0604603\ttotal: 5m 27s\tremaining: 21.6s\n",
            "938:\tlearn: 0.0604584\ttotal: 5m 27s\tremaining: 21.3s\n",
            "939:\tlearn: 0.0604439\ttotal: 5m 28s\tremaining: 20.9s\n",
            "940:\tlearn: 0.0604367\ttotal: 5m 28s\tremaining: 20.6s\n",
            "941:\tlearn: 0.0604231\ttotal: 5m 28s\tremaining: 20.2s\n",
            "942:\tlearn: 0.0603980\ttotal: 5m 29s\tremaining: 19.9s\n",
            "943:\tlearn: 0.0603964\ttotal: 5m 29s\tremaining: 19.5s\n",
            "944:\tlearn: 0.0603676\ttotal: 5m 29s\tremaining: 19.2s\n",
            "945:\tlearn: 0.0603498\ttotal: 5m 30s\tremaining: 18.8s\n",
            "946:\tlearn: 0.0603462\ttotal: 5m 30s\tremaining: 18.5s\n",
            "947:\tlearn: 0.0603303\ttotal: 5m 30s\tremaining: 18.1s\n",
            "948:\tlearn: 0.0603202\ttotal: 5m 31s\tremaining: 17.8s\n",
            "949:\tlearn: 0.0603027\ttotal: 5m 31s\tremaining: 17.4s\n",
            "950:\tlearn: 0.0602720\ttotal: 5m 31s\tremaining: 17.1s\n",
            "951:\tlearn: 0.0602601\ttotal: 5m 32s\tremaining: 16.7s\n",
            "952:\tlearn: 0.0602457\ttotal: 5m 32s\tremaining: 16.4s\n",
            "953:\tlearn: 0.0602429\ttotal: 5m 32s\tremaining: 16s\n",
            "954:\tlearn: 0.0602378\ttotal: 5m 33s\tremaining: 15.7s\n",
            "955:\tlearn: 0.0602288\ttotal: 5m 33s\tremaining: 15.3s\n",
            "956:\tlearn: 0.0602049\ttotal: 5m 33s\tremaining: 15s\n",
            "957:\tlearn: 0.0601869\ttotal: 5m 34s\tremaining: 14.7s\n",
            "958:\tlearn: 0.0601767\ttotal: 5m 34s\tremaining: 14.3s\n",
            "959:\tlearn: 0.0601583\ttotal: 5m 34s\tremaining: 14s\n",
            "960:\tlearn: 0.0601507\ttotal: 5m 35s\tremaining: 13.6s\n",
            "961:\tlearn: 0.0601238\ttotal: 5m 35s\tremaining: 13.3s\n",
            "962:\tlearn: 0.0601022\ttotal: 5m 36s\tremaining: 12.9s\n",
            "963:\tlearn: 0.0600950\ttotal: 5m 36s\tremaining: 12.6s\n",
            "964:\tlearn: 0.0600790\ttotal: 5m 36s\tremaining: 12.2s\n",
            "965:\tlearn: 0.0600633\ttotal: 5m 37s\tremaining: 11.9s\n",
            "966:\tlearn: 0.0600448\ttotal: 5m 37s\tremaining: 11.5s\n",
            "967:\tlearn: 0.0600431\ttotal: 5m 37s\tremaining: 11.2s\n",
            "968:\tlearn: 0.0600291\ttotal: 5m 38s\tremaining: 10.8s\n",
            "969:\tlearn: 0.0600205\ttotal: 5m 38s\tremaining: 10.5s\n",
            "970:\tlearn: 0.0600068\ttotal: 5m 38s\tremaining: 10.1s\n",
            "971:\tlearn: 0.0599792\ttotal: 5m 39s\tremaining: 9.77s\n",
            "972:\tlearn: 0.0599548\ttotal: 5m 39s\tremaining: 9.42s\n",
            "973:\tlearn: 0.0599333\ttotal: 5m 39s\tremaining: 9.07s\n",
            "974:\tlearn: 0.0599094\ttotal: 5m 40s\tremaining: 8.73s\n",
            "975:\tlearn: 0.0598971\ttotal: 5m 40s\tremaining: 8.38s\n",
            "976:\tlearn: 0.0598837\ttotal: 5m 41s\tremaining: 8.03s\n",
            "977:\tlearn: 0.0598789\ttotal: 5m 41s\tremaining: 7.68s\n",
            "978:\tlearn: 0.0598564\ttotal: 5m 41s\tremaining: 7.33s\n",
            "979:\tlearn: 0.0598368\ttotal: 5m 42s\tremaining: 6.99s\n",
            "980:\tlearn: 0.0598199\ttotal: 5m 42s\tremaining: 6.64s\n",
            "981:\tlearn: 0.0598125\ttotal: 5m 43s\tremaining: 6.29s\n",
            "982:\tlearn: 0.0597940\ttotal: 5m 43s\tremaining: 5.94s\n",
            "983:\tlearn: 0.0597927\ttotal: 5m 43s\tremaining: 5.59s\n",
            "984:\tlearn: 0.0597805\ttotal: 5m 44s\tremaining: 5.24s\n",
            "985:\tlearn: 0.0597655\ttotal: 5m 44s\tremaining: 4.89s\n",
            "986:\tlearn: 0.0597535\ttotal: 5m 44s\tremaining: 4.54s\n",
            "987:\tlearn: 0.0597346\ttotal: 5m 45s\tremaining: 4.19s\n",
            "988:\tlearn: 0.0597158\ttotal: 5m 45s\tremaining: 3.84s\n",
            "989:\tlearn: 0.0597014\ttotal: 5m 45s\tremaining: 3.49s\n",
            "990:\tlearn: 0.0596890\ttotal: 5m 46s\tremaining: 3.14s\n",
            "991:\tlearn: 0.0596491\ttotal: 5m 46s\tremaining: 2.79s\n",
            "992:\tlearn: 0.0596245\ttotal: 5m 46s\tremaining: 2.44s\n",
            "993:\tlearn: 0.0596027\ttotal: 5m 47s\tremaining: 2.1s\n",
            "994:\tlearn: 0.0595869\ttotal: 5m 47s\tremaining: 1.75s\n",
            "995:\tlearn: 0.0595681\ttotal: 5m 48s\tremaining: 1.4s\n",
            "996:\tlearn: 0.0595473\ttotal: 5m 48s\tremaining: 1.05s\n",
            "997:\tlearn: 0.0595332\ttotal: 5m 48s\tremaining: 699ms\n",
            "998:\tlearn: 0.0595209\ttotal: 5m 49s\tremaining: 350ms\n",
            "999:\tlearn: 0.0595150\ttotal: 5m 49s\tremaining: 0us\n",
            "<catboost.core.CatBoostClassifier object at 0x7f25454a67b8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_ztHCS-KJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc30ba20-b389-4e2c-cc0e-52925e34b0ad"
      },
      "source": [
        "# evaluate predictions\r\n",
        "accuracy = accuracy_score(y_test, predictions)\r\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\r\n",
        "print(model_catboost.get_all_params())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.03%\n",
            "{'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'subsample': 0.800000011920929, 'use_best_model': False, 'class_names': [0, 1], 'random_seed': 0, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.1324310004711151, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
